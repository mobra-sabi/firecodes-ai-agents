#!/usr/bin/env python3
"""
ðŸ” ENHANCED COMPETITOR DISCOVERY
=================================
Descoperire completÄƒ a competitorilor cu Google Search real:
- Multiple keywords per subdomeniu
- Top 10 rezultate per keyword
- Deduplicare automatÄƒ
- Tracking keywords + SERP positions
"""

import asyncio
import sys
sys.path.insert(0, '/srv/hf/ai_agents')

from typing import List, Dict, Any, Set
from pymongo import MongoClient
from bson import ObjectId
import requests
import os
from datetime import datetime, timezone
from collections import defaultdict
import json


class EnhancedCompetitorDiscovery:
    """
    Sistem avansat de descoperire competitori cu Google Search
    """
    
    def __init__(self):
        self.mongo = MongoClient("mongodb://localhost:27017/")
        self.db = self.mongo["ai_agents_db"]
        
        # Brave Search API (free tier: 2000 requests/month)
        self.brave_api_key = os.getenv("BRAVE_API_KEY", "")
        
    def brave_search(self, query: str, count: int = 10) -> List[Dict[str, Any]]:
        """
        Brave Search API - alternative la Google
        """
        if not self.brave_api_key:
            print(f"âš ï¸  No Brave API key, using mock data for: {query}")
            return self._mock_google_results(query, count)
        
        try:
            url = "https://api.search.brave.com/res/v1/web/search"
            headers = {
                "Accept": "application/json",
                "X-Subscription-Token": self.brave_api_key
            }
            params = {
                "q": query,
                "count": count,
                "country": "ALL",  # RO not supported, using ALL for global results
                "search_lang": "ro"
            }
            
            response = requests.get(url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            results = []
            
            for i, result in enumerate(data.get("web", {}).get("results", [])[:count], 1):
                results.append({
                    "url": result.get("url"),
                    "title": result.get("title"),
                    "snippet": result.get("description"),
                    "position": i
                })
            
            return results
            
        except Exception as e:
            print(f"âŒ Brave Search error for '{query}': {e}")
            return self._mock_google_results(query, count)
    
    def _mock_google_results(self, query: str, count: int = 10) -> List[Dict[str, Any]]:
        """
        Mock Google results folosind agenÈ›i existenÈ›i din DB
        (fallback cÃ¢nd nu avem API key)
        """
        # Get random agents from DB
        agents = list(self.db.site_agents.find({
            "status": "validated",
            "has_embeddings": True
        }).limit(count))
        
        results = []
        for i, agent in enumerate(agents, 1):
            results.append({
                "url": agent.get("site_url"),
                "title": f"{agent.get('domain')} - {query}",
                "snippet": f"Competitor found for {query}",
                "position": i
            })
        
        return results
    
    async def discover_all_competitors(
        self,
        master_agent_id: str,
        keywords: List[str],
        results_per_keyword: int = 10
    ) -> Dict[str, Any]:
        """
        DescoperÄƒ TOÈšI competitorii pentru toate keywords-urile
        
        Returns:
            {
                "total_searches": int,
                "total_results": int,
                "unique_competitors": int,
                "competitors": [
                    {
                        "url": str,
                        "domain": str,
                        "found_for_keywords": [str],
                        "serp_positions": {keyword: position},
                        "average_position": float,
                        "keyword_count": int
                    }
                ]
            }
        """
        print(f"ðŸ” ENHANCED COMPETITOR DISCOVERY")
        print(f"   Keywords: {len(keywords)}")
        print(f"   Results per keyword: {results_per_keyword}")
        print(f"   Expected results: ~{len(keywords) * results_per_keyword}")
        print()
        
        # Track all competitors
        competitors_map = defaultdict(lambda: {
            "url": "",
            "domain": "",
            "title": "",
            "found_for_keywords": [],
            "serp_positions": {},
            "snippets": []
        })
        
        total_searches = 0
        total_results = 0
        
        # Search for each keyword
        for i, keyword in enumerate(keywords, 1):
            print(f"   [{i}/{len(keywords)}] Searching: {keyword[:50]}...")
            
            try:
                results = self.brave_search(keyword, results_per_keyword)
                total_searches += 1
                total_results += len(results)
                
                # Process each result
                for result in results:
                    url = result.get("url")
                    if not url:
                        continue
                    
                    # Extract domain
                    from urllib.parse import urlparse
                    import tldextract
                    
                    domain = tldextract.extract(url).registered_domain
                    if not domain:
                        continue
                    
                    # Add to map (deduplicate automatically)
                    if not competitors_map[domain]["url"]:
                        competitors_map[domain]["url"] = url
                        competitors_map[domain]["domain"] = domain
                        competitors_map[domain]["title"] = result.get("title", "")
                    
                    # Track keyword and position
                    if keyword not in competitors_map[domain]["found_for_keywords"]:
                        competitors_map[domain]["found_for_keywords"].append(keyword)
                    
                    competitors_map[domain]["serp_positions"][keyword] = result.get("position", 0)
                    
                    if result.get("snippet"):
                        competitors_map[domain]["snippets"].append(result.get("snippet"))
                
            except Exception as e:
                print(f"      âŒ Error: {e}")
                continue
        
        print()
        print(f"âœ… Discovery Complete!")
        print(f"   Total searches: {total_searches}")
        print(f"   Total results: {total_results}")
        print(f"   Unique competitors: {len(competitors_map)}")
        print()
        
        # Calculate statistics for each competitor
        competitors_list = []
        for domain, data in competitors_map.items():
            # Calculate average SERP position
            positions = list(data["serp_positions"].values())
            avg_position = sum(positions) / len(positions) if positions else 0
            
            competitors_list.append({
                "url": data["url"],
                "domain": domain,
                "title": data["title"],
                "found_for_keywords": data["found_for_keywords"],
                "keyword_count": len(data["found_for_keywords"]),
                "serp_positions": data["serp_positions"],
                "average_position": round(avg_position, 1),
                "best_position": min(positions) if positions else 999,
                "worst_position": max(positions) if positions else 999,
                "snippets": data["snippets"][:3]  # Keep only first 3
            })
        
        # Sort by keyword count (most relevant first)
        competitors_list.sort(key=lambda x: (x["keyword_count"], -x["average_position"]), reverse=True)
        
        return {
            "total_searches": total_searches,
            "total_results": total_results,
            "unique_competitors": len(competitors_list),
            "competitors": competitors_list,
            "discovery_timestamp": datetime.now(timezone.utc).isoformat()
        }
    
    def save_discovery_report(
        self,
        master_agent_id: str,
        discovery_data: Dict[str, Any]
    ):
        """
        SalveazÄƒ raportul de descoperire Ã®n MongoDB
        """
        report = {
            "master_id": ObjectId(master_agent_id),
            "discovery_timestamp": datetime.now(timezone.utc),
            "total_searches": discovery_data["total_searches"],
            "total_results": discovery_data["total_results"],
            "unique_competitors": discovery_data["unique_competitors"],
            "competitors": discovery_data["competitors"]
        }
        
        # Save to MongoDB
        self.db.competitor_discovery_reports.insert_one(report)
        
        print(f"âœ… Discovery report saved to MongoDB")
        print(f"   Report ID: {report['_id']}")
    
    def print_discovery_summary(self, discovery_data: Dict[str, Any]):
        """
        Print a nice summary of the discovery
        """
        print()
        print("="*80)
        print("ðŸ“Š COMPETITOR DISCOVERY SUMMARY")
        print("="*80)
        print()
        
        print(f"Total Searches: {discovery_data['total_searches']}")
        print(f"Total Results: {discovery_data['total_results']}")
        print(f"Unique Competitors: {discovery_data['unique_competitors']}")
        print()
        
        competitors = discovery_data["competitors"]
        
        # Top 10 most relevant
        print("ðŸ† TOP 10 MOST RELEVANT COMPETITORS:")
        print("-"*80)
        for i, comp in enumerate(competitors[:10], 1):
            print(f"{i:2}. {comp['domain']:30} | {comp['keyword_count']:3} keywords | Avg Pos: {comp['average_position']:4.1f}")
        print()
        
        # Show detailed info for top 3
        print("ðŸ“‹ DETAILED INFO FOR TOP 3:")
        print("-"*80)
        for i, comp in enumerate(competitors[:3], 1):
            print(f"\n{i}. {comp['domain']}")
            print(f"   URL: {comp['url']}")
            print(f"   Found for {comp['keyword_count']} keywords:")
            for kw in comp['found_for_keywords'][:5]:
                pos = comp['serp_positions'].get(kw, '?')
                print(f"      - {kw[:50]:50} (Position: #{pos})")
            if len(comp['found_for_keywords']) > 5:
                print(f"      ... and {len(comp['found_for_keywords']) - 5} more keywords")
            print(f"   Average Position: {comp['average_position']}")
            print(f"   Best Position: #{comp['best_position']}")
        
        print()
        print("="*80)


async def main():
    """
    Test enhanced competitor discovery
    """
    discovery = EnhancedCompetitorDiscovery()
    
    # Test keywords
    test_keywords = [
        "renovare apartament bucuresti",
        "pret renovare apartament",
        "firma renovari",
        "amenajari interioare",
        "constructii case",
        "firma constructii",
        "renovare la cheie",
        "proiect renovare",
        "design interior",
        "renovari complete"
    ]
    
    print("ðŸš€ Testing Enhanced Competitor Discovery")
    print()
    
    discovery_data = await discovery.discover_all_competitors(
        master_agent_id="test",
        keywords=test_keywords,
        results_per_keyword=10
    )
    
    discovery.print_discovery_summary(discovery_data)


if __name__ == "__main__":
    asyncio.run(main())

