import asyncio
import os
import logging
from datetime import datetime, timezone
from pymongo import MongoClient
from bson import ObjectId
import sys

# AdÄƒugÄƒm calea curentÄƒ la path
sys.path.append(os.getcwd())

from ceo_master_workflow import CEOMasterWorkflow

# Configurare Logger
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("logs/turbo_finish.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("TurboFinish")

async def main():
    MONGO_URI = os.getenv("MONGODB_URI", "mongodb://localhost:27018/")
    client = MongoClient(MONGO_URI)
    db = client['ai_agents_db']
    
    DOMAIN = "hidroizolatii-terase.ro"
    PARALLEL_COUNT = 12 # FORÈšÄ‚M NOTA - avem 8 GPU-uri de top!
    
    logger.info(f"ğŸš€ Pornire TURBO FINISH pentru {DOMAIN} cu {PARALLEL_COUNT} workers")
    
    # 1. GÄƒseÈ™te Master Agent
    master = db.site_agents.find_one({"domain": DOMAIN, "agent_type": "master"})
    if not master:
        logger.error(f"âŒ Master agent not found for {DOMAIN}")
        return
        
    master_id = str(master["_id"])
    logger.info(f"âœ… Master Agent gÄƒsit: {master_id}")
    
    # 2. GÄƒseÈ™te lista de competitori descoperiÈ›i (din Faza 5)
    discovery_doc = db.competitor_discoveries.find_one(
        {"agent_id": master["_id"]}, 
        sort=[("created_at", -1)]
    )
    
    if not discovery_doc or "discovery_data" not in discovery_doc:
        logger.error("âŒ Nu s-au gÄƒsit date de discovery (competitori). RulaÈ›i workflow-ul normal.")
        return
        
    all_competitors = discovery_doc["discovery_data"].get("competitors", [])
    logger.info(f"ğŸ“Š Total competitori descoperiÈ›i iniÈ›ial: {len(all_competitors)}")
    
    # 3. VerificÄƒ ce agenÈ›i existÄƒ deja
    existing_slaves = list(db.site_agents.find(
        {"master_agent_id": master["_id"], "agent_type": "slave"},
        {"site_url": 1}
    ))
    existing_urls = {s.get("site_url") for s in existing_slaves}
    
    logger.info(f"âœ… AgenÈ›i deja creaÈ›i: {len(existing_urls)}")
    
    # 4. FiltreazÄƒ doar cei rÄƒmaÈ™i
    remaining_competitors = [
        c for c in all_competitors 
        if c.get("url") not in existing_urls
    ]
    
    if not remaining_competitors:
        logger.info("ğŸ‰ ToÈ›i agenÈ›ii sunt deja creaÈ›i! Nimic de fÄƒcut.")
        return
        
    logger.info(f"ğŸ”¥ RÄ‚MAÈ˜I DE PROCESAT: {len(remaining_competitors)}")
    
    # 5. ExecutÄƒ procesare paralelÄƒ
    workflow = CEOMasterWorkflow()
    
    # InjectÄƒm direct Ã®n faza 7
    logger.info("âš¡ Lansare execuÈ›ie paralelÄƒ...")
    result = await workflow._phase7_create_competitor_agents_parallel(
        competitors=remaining_competitors,
        parallel_count=PARALLEL_COUNT,
        master_agent_id=master_id
    )
    
    if result.get("success"):
        logger.info("âœ… Procesare TURBO finalizatÄƒ cu succes!")
        
        # Facem È™i organigrama finalÄƒ
        slave_ids = result.get("agent_ids", [])
        # AdÄƒugÄƒm È™i pe cei vechi la listÄƒ
        slave_ids.extend([str(s["_id"]) for s in existing_slaves])
        
        logger.info("Generare organigramÄƒ finalÄƒ...")
        await workflow._phase8_create_master_slave_orgchart(master_id, slave_ids)
        
    else:
        logger.error(f"âŒ Eroare la procesare: {result.get('error')}")

if __name__ == "__main__":
    # SetÄƒm GPU corect pentru embeddings (evitÄƒm conflict cu vLLM)
    os.environ["CUDA_VISIBLE_DEVICES"] = "8,9" 
    asyncio.run(main())

