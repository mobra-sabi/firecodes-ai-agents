{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 718,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013934854554955583,
      "grad_norm": 1.0402249097824097,
      "learning_rate": 9.874651810584958e-05,
      "loss": 2.5012,
      "step": 10
    },
    {
      "epoch": 0.027869709109911166,
      "grad_norm": 1.532283067703247,
      "learning_rate": 9.749303621169918e-05,
      "loss": 2.2522,
      "step": 20
    },
    {
      "epoch": 0.04180456366486675,
      "grad_norm": 0.8244261145591736,
      "learning_rate": 9.610027855153204e-05,
      "loss": 1.9784,
      "step": 30
    },
    {
      "epoch": 0.05573941821982233,
      "grad_norm": 0.8219156861305237,
      "learning_rate": 9.470752089136491e-05,
      "loss": 1.7405,
      "step": 40
    },
    {
      "epoch": 0.06967427277477792,
      "grad_norm": 1.6672577857971191,
      "learning_rate": 9.331476323119777e-05,
      "loss": 1.3403,
      "step": 50
    },
    {
      "epoch": 0.0836091273297335,
      "grad_norm": 3.5393168926239014,
      "learning_rate": 9.192200557103065e-05,
      "loss": 1.1688,
      "step": 60
    },
    {
      "epoch": 0.09754398188468907,
      "grad_norm": 4.900347709655762,
      "learning_rate": 9.052924791086351e-05,
      "loss": 0.9312,
      "step": 70
    },
    {
      "epoch": 0.11147883643964467,
      "grad_norm": 2.806964635848999,
      "learning_rate": 8.913649025069638e-05,
      "loss": 0.6366,
      "step": 80
    },
    {
      "epoch": 0.12541369099460026,
      "grad_norm": 2.8791675567626953,
      "learning_rate": 8.774373259052925e-05,
      "loss": 0.5335,
      "step": 90
    },
    {
      "epoch": 0.13934854554955584,
      "grad_norm": 1.688429355621338,
      "learning_rate": 8.635097493036212e-05,
      "loss": 0.3654,
      "step": 100
    },
    {
      "epoch": 0.1532834001045114,
      "grad_norm": 2.5947418212890625,
      "learning_rate": 8.4958217270195e-05,
      "loss": 0.5045,
      "step": 110
    },
    {
      "epoch": 0.167218254659467,
      "grad_norm": 1.0269944667816162,
      "learning_rate": 8.356545961002787e-05,
      "loss": 0.3568,
      "step": 120
    },
    {
      "epoch": 0.18115310921442257,
      "grad_norm": 1.1174952983856201,
      "learning_rate": 8.217270194986073e-05,
      "loss": 0.3091,
      "step": 130
    },
    {
      "epoch": 0.19508796376937815,
      "grad_norm": 0.7517553567886353,
      "learning_rate": 8.07799442896936e-05,
      "loss": 0.2666,
      "step": 140
    },
    {
      "epoch": 0.20902281832433375,
      "grad_norm": 0.9993590712547302,
      "learning_rate": 7.938718662952647e-05,
      "loss": 0.2656,
      "step": 150
    },
    {
      "epoch": 0.22295767287928933,
      "grad_norm": 1.6041067838668823,
      "learning_rate": 7.799442896935933e-05,
      "loss": 0.3825,
      "step": 160
    },
    {
      "epoch": 0.2368925274342449,
      "grad_norm": 0.5371747612953186,
      "learning_rate": 7.66016713091922e-05,
      "loss": 0.2578,
      "step": 170
    },
    {
      "epoch": 0.2508273819892005,
      "grad_norm": 0.8807100653648376,
      "learning_rate": 7.520891364902506e-05,
      "loss": 0.2612,
      "step": 180
    },
    {
      "epoch": 0.2647622365441561,
      "grad_norm": 1.2390737533569336,
      "learning_rate": 7.381615598885794e-05,
      "loss": 0.2978,
      "step": 190
    },
    {
      "epoch": 0.27869709109911167,
      "grad_norm": 0.7308500409126282,
      "learning_rate": 7.24233983286908e-05,
      "loss": 0.2679,
      "step": 200
    },
    {
      "epoch": 0.29263194565406725,
      "grad_norm": 0.462432324886322,
      "learning_rate": 7.103064066852369e-05,
      "loss": 0.2678,
      "step": 210
    },
    {
      "epoch": 0.3065668002090228,
      "grad_norm": 0.5518682599067688,
      "learning_rate": 6.963788300835655e-05,
      "loss": 0.1798,
      "step": 220
    },
    {
      "epoch": 0.3205016547639784,
      "grad_norm": 0.5004141926765442,
      "learning_rate": 6.824512534818942e-05,
      "loss": 0.3662,
      "step": 230
    },
    {
      "epoch": 0.334436509318934,
      "grad_norm": 0.6165928244590759,
      "learning_rate": 6.685236768802228e-05,
      "loss": 0.3853,
      "step": 240
    },
    {
      "epoch": 0.34837136387388956,
      "grad_norm": 1.0689654350280762,
      "learning_rate": 6.545961002785516e-05,
      "loss": 0.3165,
      "step": 250
    },
    {
      "epoch": 0.36230621842884514,
      "grad_norm": 1.5599758625030518,
      "learning_rate": 6.406685236768802e-05,
      "loss": 0.2634,
      "step": 260
    },
    {
      "epoch": 0.3762410729838007,
      "grad_norm": 0.35903072357177734,
      "learning_rate": 6.26740947075209e-05,
      "loss": 0.3364,
      "step": 270
    },
    {
      "epoch": 0.3901759275387563,
      "grad_norm": 0.4842798113822937,
      "learning_rate": 6.128133704735376e-05,
      "loss": 0.28,
      "step": 280
    },
    {
      "epoch": 0.4041107820937119,
      "grad_norm": 0.446909099817276,
      "learning_rate": 5.9888579387186624e-05,
      "loss": 0.1965,
      "step": 290
    },
    {
      "epoch": 0.4180456366486675,
      "grad_norm": 0.48795750737190247,
      "learning_rate": 5.8495821727019506e-05,
      "loss": 0.1278,
      "step": 300
    },
    {
      "epoch": 0.4319804912036231,
      "grad_norm": 0.7343209981918335,
      "learning_rate": 5.7103064066852374e-05,
      "loss": 0.3104,
      "step": 310
    },
    {
      "epoch": 0.44591534575857866,
      "grad_norm": 0.740865170955658,
      "learning_rate": 5.571030640668524e-05,
      "loss": 0.34,
      "step": 320
    },
    {
      "epoch": 0.45985020031353424,
      "grad_norm": 0.6807928085327148,
      "learning_rate": 5.431754874651811e-05,
      "loss": 0.2286,
      "step": 330
    },
    {
      "epoch": 0.4737850548684898,
      "grad_norm": 0.3796931505203247,
      "learning_rate": 5.292479108635098e-05,
      "loss": 0.1543,
      "step": 340
    },
    {
      "epoch": 0.4877199094234454,
      "grad_norm": 0.6166909337043762,
      "learning_rate": 5.1532033426183846e-05,
      "loss": 0.2971,
      "step": 350
    },
    {
      "epoch": 0.501654763978401,
      "grad_norm": 0.45797523856163025,
      "learning_rate": 5.0139275766016714e-05,
      "loss": 0.3122,
      "step": 360
    },
    {
      "epoch": 0.5155896185333566,
      "grad_norm": 0.5267898440361023,
      "learning_rate": 4.874651810584959e-05,
      "loss": 0.2634,
      "step": 370
    },
    {
      "epoch": 0.5295244730883122,
      "grad_norm": 0.7000317573547363,
      "learning_rate": 4.7353760445682456e-05,
      "loss": 0.2739,
      "step": 380
    },
    {
      "epoch": 0.5434593276432678,
      "grad_norm": 0.5568981766700745,
      "learning_rate": 4.5961002785515324e-05,
      "loss": 0.2455,
      "step": 390
    },
    {
      "epoch": 0.5573941821982233,
      "grad_norm": 0.8033958077430725,
      "learning_rate": 4.456824512534819e-05,
      "loss": 0.3697,
      "step": 400
    },
    {
      "epoch": 0.5713290367531789,
      "grad_norm": 0.6405804753303528,
      "learning_rate": 4.317548746518106e-05,
      "loss": 0.2678,
      "step": 410
    },
    {
      "epoch": 0.5852638913081345,
      "grad_norm": 0.5993586778640747,
      "learning_rate": 4.1782729805013935e-05,
      "loss": 0.1746,
      "step": 420
    },
    {
      "epoch": 0.5991987458630901,
      "grad_norm": 0.5459276437759399,
      "learning_rate": 4.03899721448468e-05,
      "loss": 0.2991,
      "step": 430
    },
    {
      "epoch": 0.6131336004180457,
      "grad_norm": 1.5150171518325806,
      "learning_rate": 3.8997214484679664e-05,
      "loss": 0.141,
      "step": 440
    },
    {
      "epoch": 0.6270684549730012,
      "grad_norm": 0.5036863684654236,
      "learning_rate": 3.760445682451253e-05,
      "loss": 0.2003,
      "step": 450
    },
    {
      "epoch": 0.6410033095279568,
      "grad_norm": 0.6881487965583801,
      "learning_rate": 3.62116991643454e-05,
      "loss": 0.2672,
      "step": 460
    },
    {
      "epoch": 0.6549381640829124,
      "grad_norm": 0.5325228571891785,
      "learning_rate": 3.4818941504178274e-05,
      "loss": 0.2368,
      "step": 470
    },
    {
      "epoch": 0.668873018637868,
      "grad_norm": 0.8094058036804199,
      "learning_rate": 3.342618384401114e-05,
      "loss": 0.308,
      "step": 480
    },
    {
      "epoch": 0.6828078731928235,
      "grad_norm": 0.6391180157661438,
      "learning_rate": 3.203342618384401e-05,
      "loss": 0.3162,
      "step": 490
    },
    {
      "epoch": 0.6967427277477791,
      "grad_norm": 0.38250821828842163,
      "learning_rate": 3.064066852367688e-05,
      "loss": 0.2249,
      "step": 500
    },
    {
      "epoch": 0.7106775823027347,
      "grad_norm": 0.5709104537963867,
      "learning_rate": 2.9247910863509753e-05,
      "loss": 0.2349,
      "step": 510
    },
    {
      "epoch": 0.7246124368576903,
      "grad_norm": 0.418638676404953,
      "learning_rate": 2.785515320334262e-05,
      "loss": 0.2243,
      "step": 520
    },
    {
      "epoch": 0.7385472914126459,
      "grad_norm": 0.7955244183540344,
      "learning_rate": 2.646239554317549e-05,
      "loss": 0.1728,
      "step": 530
    },
    {
      "epoch": 0.7524821459676014,
      "grad_norm": 0.6039685606956482,
      "learning_rate": 2.5069637883008357e-05,
      "loss": 0.2755,
      "step": 540
    },
    {
      "epoch": 0.766417000522557,
      "grad_norm": 0.33479541540145874,
      "learning_rate": 2.3676880222841228e-05,
      "loss": 0.2339,
      "step": 550
    },
    {
      "epoch": 0.7803518550775126,
      "grad_norm": 0.6033718585968018,
      "learning_rate": 2.2284122562674096e-05,
      "loss": 0.1529,
      "step": 560
    },
    {
      "epoch": 0.7942867096324682,
      "grad_norm": 0.7389626502990723,
      "learning_rate": 2.0891364902506967e-05,
      "loss": 0.3289,
      "step": 570
    },
    {
      "epoch": 0.8082215641874237,
      "grad_norm": 0.7018023729324341,
      "learning_rate": 1.9498607242339832e-05,
      "loss": 0.2516,
      "step": 580
    },
    {
      "epoch": 0.8221564187423793,
      "grad_norm": 0.5660496950149536,
      "learning_rate": 1.81058495821727e-05,
      "loss": 0.5031,
      "step": 590
    },
    {
      "epoch": 0.836091273297335,
      "grad_norm": 0.42902901768684387,
      "learning_rate": 1.671309192200557e-05,
      "loss": 0.1802,
      "step": 600
    },
    {
      "epoch": 0.8500261278522906,
      "grad_norm": 0.29979604482650757,
      "learning_rate": 1.532033426183844e-05,
      "loss": 0.1562,
      "step": 610
    },
    {
      "epoch": 0.8639609824072462,
      "grad_norm": 0.5337276458740234,
      "learning_rate": 1.392757660167131e-05,
      "loss": 0.1596,
      "step": 620
    },
    {
      "epoch": 0.8778958369622017,
      "grad_norm": 0.47071075439453125,
      "learning_rate": 1.2534818941504178e-05,
      "loss": 0.2971,
      "step": 630
    },
    {
      "epoch": 0.8918306915171573,
      "grad_norm": 0.2992107570171356,
      "learning_rate": 1.1142061281337048e-05,
      "loss": 0.3243,
      "step": 640
    },
    {
      "epoch": 0.9057655460721129,
      "grad_norm": 0.4391682744026184,
      "learning_rate": 9.749303621169916e-06,
      "loss": 0.1509,
      "step": 650
    },
    {
      "epoch": 0.9197004006270685,
      "grad_norm": 0.56943678855896,
      "learning_rate": 8.356545961002786e-06,
      "loss": 0.2359,
      "step": 660
    },
    {
      "epoch": 0.9336352551820241,
      "grad_norm": 0.3529975116252899,
      "learning_rate": 6.963788300835655e-06,
      "loss": 0.3879,
      "step": 670
    },
    {
      "epoch": 0.9475701097369796,
      "grad_norm": 0.47500911355018616,
      "learning_rate": 5.571030640668524e-06,
      "loss": 0.2289,
      "step": 680
    },
    {
      "epoch": 0.9615049642919352,
      "grad_norm": 0.3597430884838104,
      "learning_rate": 4.178272980501393e-06,
      "loss": 0.3103,
      "step": 690
    },
    {
      "epoch": 0.9754398188468908,
      "grad_norm": 0.3698942959308624,
      "learning_rate": 2.785515320334262e-06,
      "loss": 0.2655,
      "step": 700
    },
    {
      "epoch": 0.9893746734018464,
      "grad_norm": 0.40738582611083984,
      "learning_rate": 1.392757660167131e-06,
      "loss": 0.2382,
      "step": 710
    }
  ],
  "logging_steps": 10,
  "max_steps": 718,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.157402954170368e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
