#!/usr/bin/env python3
"""
ğŸš€ PROCESARE PARALELÄ‚ AGENÈšI CU MULTIPLE GPU-uri
================================================

ProceseazÄƒ agenÈ›ii Ã®n paralel folosind:
- vLLM pe portul 9301 pentru LLM inference
- GPU 6-10 pentru embeddings (1 agent per GPU)
- MongoDB È™i Qdrant pentru storage

USAGE:
    python3 parallel_agent_processor.py
"""

import torch
import multiprocessing as mp
from pymongo import MongoClient
from bson import ObjectId
import sys
import os
import time
from datetime import datetime
sys.path.insert(0, '/srv/hf/ai_agents')

# Import modulele necesare
from tools.construction_agent_creator import ConstructionAgentCreator
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct

def process_agent_on_gpu(gpu_id: int, agent_data: dict, results_queue: mp.Queue):
    """
    ProceseazÄƒ un agent pe un GPU specific
    
    Args:
        gpu_id: ID-ul GPU-ului (6-10)
        agent_data: Dict cu agent_id, domain, site_url
        results_queue: Queue pentru rezultate
    """
    try:
        # Set GPU
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        device = f"cuda:0"  # DupÄƒ setare, devine primul GPU disponibil
        
        agent_id = agent_data['agent_id']
        domain = agent_data['domain']
        site_url = agent_data['site_url']
        
        print(f"\n{'='*70}")
        print(f"ğŸ® GPU {gpu_id} | Agent: {domain}")
        print(f"{'='*70}")
        print(f"   Agent ID: {agent_id}")
        print(f"   URL: {site_url}")
        print(f"   Start: {datetime.now().strftime('%H:%M:%S')}")
        
        # STEP 1: CreeazÄƒ agent cu construction_agent_creator
        # (foloseÈ™te vLLM 9301 pentru LLM calls)
        print(f"\n[GPU {gpu_id}] STEP 1/3: Creare agent cu construction_agent_creator...")
        creator = ConstructionAgentCreator()
        creator.create_site_agent(site_url)
        
        # STEP 2: Extrage conÈ›inut din MongoDB
        print(f"\n[GPU {gpu_id}] STEP 2/3: Extragere conÈ›inut din MongoDB...")
        mongo = MongoClient("mongodb://localhost:27017/")
        db = mongo.ai_agents_db
        
        # GÄƒseÈ™te agentul creat
        agent = db.site_agents.find_one({'domain': domain}, sort=[("created_at", -1)])
        if not agent:
            raise Exception(f"Agent {domain} nu gÄƒsit Ã®n MongoDB")
        
        agent_id_obj = agent['_id']
        contents = list(db.site_content.find({"agent_id": agent_id_obj}))
        
        if not contents:
            print(f"[GPU {gpu_id}] âš ï¸  Nu existÄƒ conÈ›inut pentru procesare")
            results_queue.put({
                'success': False,
                'gpu_id': gpu_id,
                'domain': domain,
                'error': 'No content found'
            })
            return
        
        print(f"[GPU {gpu_id}]    GÄƒsite {len(contents)} chunks de conÈ›inut")
        
        # STEP 3: GenereazÄƒ embeddings pe GPU
        print(f"\n[GPU {gpu_id}] STEP 3/3: Generare embeddings pe GPU {gpu_id}...")
        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)
        
        texts = [c['content'] for c in contents if c.get('content')]
        
        start_time = time.time()
        embeddings = model.encode(
            texts,
            batch_size=32,
            show_progress_bar=False,
            convert_to_numpy=True
        )
        elapsed = time.time() - start_time
        
        print(f"[GPU {gpu_id}]    âœ… {len(embeddings)} embeddings Ã®n {elapsed:.1f}s ({len(texts)/elapsed:.1f} txt/s)")
        
        # STEP 4: Upload la Qdrant
        print(f"\n[GPU {gpu_id}] STEP 4/4: Upload cÄƒtre Qdrant...")
        qdrant = QdrantClient(url="http://localhost:9306")
        collection_name = f"agent_{agent_id_obj}_content"
        
        # Recreate collection
        try:
            qdrant.delete_collection(collection_name=collection_name)
        except:
            pass
        
        qdrant.create_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(size=384, distance=Distance.COSINE)
        )
        
        # Upload points
        points = []
        for idx, (content, embedding) in enumerate(zip(contents, embeddings)):
            points.append(PointStruct(
                id=idx,
                vector=embedding.tolist(),
                payload={
                    "text": content['content'][:1000],
                    "url": content.get('url', ''),
                    "agent_id": str(agent_id_obj),
                    "chunk_index": idx
                }
            ))
        
        qdrant.upsert(collection_name=collection_name, points=points)
        
        # Update agent Ã®n MongoDB
        db.site_agents.update_one(
            {"_id": agent_id_obj},
            {"$set": {
                "chunks_indexed": len(points),
                "pages_indexed": len(set(c.get('url', '') for c in contents)),
                "has_embeddings": True,
                "status": "active",
                "last_processed": datetime.now()
            }}
        )
        
        print(f"\n[GPU {gpu_id}] âœ… SUCCES: {domain}")
        print(f"[GPU {gpu_id}]    Chunks: {len(points)}")
        print(f"[GPU {gpu_id}]    Timp total: {time.time() - start_time:.1f}s")
        
        results_queue.put({
            'success': True,
            'gpu_id': gpu_id,
            'domain': domain,
            'chunks': len(points),
            'pages': len(set(c.get('url', '') for c in contents))
        })
        
    except Exception as e:
        print(f"\n[GPU {gpu_id}] âŒ EROARE: {domain}")
        print(f"[GPU {gpu_id}]    {str(e)}")
        import traceback
        traceback.print_exc()
        
        results_queue.put({
            'success': False,
            'gpu_id': gpu_id,
            'domain': domain,
            'error': str(e)
        })


def get_agents_to_process(limit=5):
    """ObÈ›ine agenÈ›ii care au nevoie de procesare"""
    mongo = MongoClient("mongodb://localhost:27017/")
    db = mongo.ai_agents_db
    
    # GÄƒseÈ™te agenÈ›ii fÄƒrÄƒ date complete
    agents = list(db.site_agents.find({
        '$or': [
            {'chunks_indexed': {'$exists': False}},
            {'chunks_indexed': 0},
            {'pages_indexed': 0}
        ]
    }).limit(limit))
    
    return [{
        'agent_id': str(agent['_id']),
        'domain': agent.get('domain', 'N/A'),
        'site_url': agent.get('site_url', f"https://{agent.get('domain', '')}")
    } for agent in agents]


def main():
    """Main function pentru procesare paralelÄƒ"""
    
    print("\n" + "="*80)
    print("ğŸš€ PROCESARE PARALELÄ‚ AGENÈšI - MULTI-GPU")
    print("="*80)
    print(f"â° Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # VerificÄƒ GPU-uri disponibile
    if not torch.cuda.is_available():
        print("âŒ CUDA nu este disponibil!")
        return
    
    total_gpus = torch.cuda.device_count()
    print(f"\nğŸ® GPU-uri detectate: {total_gpus}")
    
    # Folosim GPU 6-10 (5 GPU-uri pentru procesare paralelÄƒ)
    worker_gpus = list(range(6, min(11, total_gpus)))
    print(f"   GPU-uri pentru procesare: {worker_gpus}")
    
    if not worker_gpus:
        print("âŒ Nu existÄƒ GPU-uri libere pentru procesare!")
        return
    
    # ObÈ›ine agenÈ›i de procesare
    agents_to_process = get_agents_to_process(limit=len(worker_gpus))
    
    if not agents_to_process:
        print("\nâœ… Nu existÄƒ agenÈ›i de procesare!")
        return
    
    print(f"\nğŸ“Š AgenÈ›i de procesat: {len(agents_to_process)}")
    for i, agent in enumerate(agents_to_process, 1):
        print(f"   {i}. {agent['domain']}")
    
    # Procesare paralelÄƒ
    print(f"\n{'='*80}")
    print(f"ğŸš€ PORNESC PROCESARE PARALELÄ‚ PE {len(worker_gpus)} GPU-uri")
    print(f"{'='*80}\n")
    
    results_queue = mp.Queue()
    processes = []
    
    start_time = time.time()
    
    # PorneÈ™te cÃ¢te un proces per GPU
    for gpu_id, agent_data in zip(worker_gpus, agents_to_process):
        p = mp.Process(
            target=process_agent_on_gpu,
            args=(gpu_id, agent_data, results_queue)
        )
        p.start()
        processes.append(p)
        time.sleep(2)  # Stagger start
    
    # AÈ™teaptÄƒ finalizarea
    for p in processes:
        p.join()
    
    # ColecteazÄƒ rezultate
    results = []
    while not results_queue.empty():
        results.append(results_queue.get())
    
    elapsed = time.time() - start_time
    
    # Raport final
    print(f"\n{'='*80}")
    print(f"ğŸ“Š RAPORT FINAL PROCESARE PARALELÄ‚")
    print(f"{'='*80}")
    print(f"\nâ±ï¸  Timp total: {elapsed/60:.1f} minute")
    print(f"ğŸ“Š Rezultate:")
    
    success_count = sum(1 for r in results if r['success'])
    failed_count = len(results) - success_count
    
    print(f"   âœ… Succese: {success_count}")
    print(f"   âŒ EÈ™uÄƒri: {failed_count}")
    
    print(f"\nğŸ“ Detalii:")
    for result in sorted(results, key=lambda x: x['gpu_id']):
        gpu_id = result['gpu_id']
        domain = result['domain']
        if result['success']:
            chunks = result['chunks']
            pages = result['pages']
            print(f"   âœ… GPU {gpu_id} | {domain}: {chunks} chunks, {pages} pages")
        else:
            error = result.get('error', 'Unknown')
            print(f"   âŒ GPU {gpu_id} | {domain}: {error}")
    
    print(f"\n{'='*80}\n")


if __name__ == "__main__":
    # NecesarÄƒ pentru multiprocessing pe Linux
    mp.set_start_method('spawn', force=True)
    main()

