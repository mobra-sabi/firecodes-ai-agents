#!/usr/bin/env python3
"""
üß™ TEST KIMI K2 INTEGRATION
===========================

Test Moonshot AI Kimi integration √Æn LLM Orchestrator
"""

import sys
sys.path.insert(0, '/srv/hf/ai_agents')

from llm_orchestrator import get_orchestrator
import json

def print_banner():
    print("=" * 80)
    print("üß™ TEST KIMI K2 (Moonshot AI) INTEGRATION")
    print("=" * 80)
    print()

def test_orchestrator_status():
    """Test 1: VerificƒÉ status orchestrator"""
    print("üìä TEST 1: Orchestrator Status")
    print("-" * 80)
    
    orchestrator = get_orchestrator()
    status = orchestrator.get_stats()
    
    print(json.dumps(status, indent=2))
    print()
    
    if "kimi" in status.get("fallback_chain", []):
        print("‚úÖ Kimi is integrated in fallback chain")
    else:
        print("‚ùå Kimi NOT in fallback chain")
    
    print()

def test_kimi_chat():
    """Test 2: Chat simplu cu Kimi"""
    print("üí¨ TEST 2: Kimi Chat (Simple)")
    print("-" * 80)
    
    orchestrator = get_orchestrator()
    
    # Check if Kimi API key is configured
    if not orchestrator.kimi_client:
        print("‚ö†Ô∏è  KIMI API KEY NOT CONFIGURED")
        print("   Set KIMI_API_KEY environment variable:")
        print("   export KIMI_API_KEY='your-moonshot-api-key'")
        print()
        print("   Or use OpenRouter/Together AI")
        print()
        return False
    
    try:
        response = orchestrator.chat(
            messages=[
                {"role": "user", "content": "ExplicƒÉ √Æntr-o propozi»õie ce este competitive intelligence"}
            ],
            model="kimi",
            temperature=0.7,
            max_tokens=100
        )
        
        if response["success"]:
            print("‚úÖ Kimi Response:")
            print(f"   Provider: {response['provider']}")
            print(f"   Model: {response['model']}")
            print(f"   Tokens: {response['tokens']}")
            if "context_window" in response:
                print(f"   Context: {response['context_window']}")
            print()
            print(f"   Content: {response['content'][:200]}...")
            print()
            return True
        else:
            print(f"‚ùå Kimi Failed: {response.get('error', 'Unknown error')}")
            print()
            return False
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print()
        return False

def test_large_content():
    """Test 3: Procesare con»õinut mare cu Kimi"""
    print("üìÑ TEST 3: Large Content Processing (200K context)")
    print("-" * 80)
    
    orchestrator = get_orchestrator()
    
    if not orchestrator.kimi_client:
        print("‚ö†Ô∏è  Skipped (no API key)")
        print()
        return False
    
    # SimuleazƒÉ un site cu mult con»õinut
    large_content = """
    DESPRE NOI:
    Suntem o companie de construc»õii specializatƒÉ √Æn renovƒÉri »ôi case noi.
    Oferim servicii complete: proiectare, construc»õie, amenajƒÉri interioare.
    
    SERVICII:
    1. Construc»õie case noi
    2. RenovƒÉri complete
    3. AmenajƒÉri interioare
    4. Instala»õii termice »ôi sanitare
    5. Acoperi»ôuri
    6. Izola»õii termice
    
    PORTOFOLIU:
    - Case reziden»õiale: 150+ proiecte
    - RenovƒÉri apartamente: 300+ proiecte
    - Comercial: 50+ proiecte
    
    ECHIPA:
    - Arhitec»õi: 5
    - Ingineri: 10
    - Muncitori: 50+
    
    ZONE ACOPERITE:
    Bucure»ôti, Ilfov, Prahova, Bra»ôov
    
    CERTIFICƒÇRI:
    ISO 9001, ISO 14001, ANRE
    """ * 20  # RepetƒÉ pentru a simula con»õinut mare
    
    try:
        response = orchestrator.process_large_content(
            content=large_content,
            task="AnalizeazƒÉ acest site »ôi identificƒÉ: 1) Subdomeniile principale, 2) 5 keywords per subdomeniu",
            model="kimi",
            temperature=0.7
        )
        
        if response["success"]:
            print("‚úÖ Large Content Processing:")
            print(f"   Provider: {response['provider']}")
            print(f"   Tokens: {response['tokens']}")
            print()
            print(f"   Response Preview:")
            print(f"   {response['content'][:300]}...")
            print()
            return True
        else:
            print(f"‚ùå Failed: {response.get('error', 'Unknown error')}")
            print()
            return False
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print()
        return False

def test_auto_fallback():
    """Test 4: Auto fallback cu Kimi √Æn lan»õ"""
    print("üîÑ TEST 4: Auto Fallback Chain")
    print("-" * 80)
    
    orchestrator = get_orchestrator()
    
    print("Testing fallback order:")
    print("1. DeepSeek")
    print("2. Kimi (200K context) ‚Üê NEW!")
    print("3. OpenAI")
    print("4. Qwen local")
    print()
    
    try:
        response = orchestrator.chat(
            messages=[
                {"role": "user", "content": "Ce este un site web?"}
            ],
            model="auto",  # Automat √ÆncearcƒÉ √Æn ordine
            temperature=0.7,
            max_tokens=50
        )
        
        print(f"‚úÖ Response from: {response['provider']}")
        print(f"   Model: {response['model']}")
        print(f"   Content: {response['content'][:100]}...")
        print()
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print()
        return False

def test_statistics():
    """Test 5: Statistici folosire"""
    print("üìä TEST 5: Usage Statistics")
    print("-" * 80)
    
    orchestrator = get_orchestrator()
    stats = orchestrator.get_stats()
    
    print("LLM Usage Statistics:")
    print(f"   Total Calls: {stats['total_calls']}")
    print(f"   DeepSeek: {stats['deepseek_successes']}/{stats['deepseek_calls']}")
    print(f"   Kimi: {stats['kimi_successes']}/{stats['kimi_calls']} ‚Üê NEW!")
    print(f"   OpenAI: {stats['openai_successes']}/{stats['openai_calls']}")
    print(f"   Qwen: {stats['qwen_successes']}/{stats['qwen_calls']}")
    print(f"   Success Rate: {stats.get('success_rate', 0)}%")
    print()

def main():
    """Run all tests"""
    print_banner()
    
    results = {
        "orchestrator_status": test_orchestrator_status(),
        "kimi_chat": test_kimi_chat(),
        "large_content": test_large_content(),
        "auto_fallback": test_auto_fallback()
    }
    
    test_statistics()
    
    print("=" * 80)
    print("üèÅ TEST RESULTS")
    print("=" * 80)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL/SKIP"
        print(f"{status} - {test_name}")
    
    print()
    
    passed = sum(1 for r in results.values() if r)
    total = len(results)
    
    print(f"üìä Summary: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ ALL TESTS PASSED!")
    elif passed > 0:
        print("‚ö†Ô∏è  SOME TESTS FAILED - Check Kimi API key configuration")
    else:
        print("‚ùå ALL TESTS FAILED - Kimi API key not configured")
    
    print()
    print("üí° To configure Kimi:")
    print("   export KIMI_API_KEY='your-moonshot-api-key'")
    print("   Or see KIMI_INTEGRATION.md for details")
    print()

if __name__ == "__main__":
    main()

