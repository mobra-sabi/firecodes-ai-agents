#!/usr/bin/env python3
"""
Qwen Memory - Memorie persistentÄƒ pentru Qwen learning
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone
from pymongo import MongoClient
from bson import ObjectId
import requests

logger = logging.getLogger(__name__)

class QwenMemory:
    """Memorie persistentÄƒ pentru Qwen learning"""
    
    def __init__(self, agent_id: str = None):
        """
        IniÈ›ializeazÄƒ Qwen Memory pentru un agent specific
        
        Args:
            agent_id: ID-ul agentului (None pentru global)
        """
        self.agent_id = agent_id
        self.mongodb_uri = "mongodb://localhost:27017"
        self.qwen_url = "http://localhost:11434"
        self.mongo_client = MongoClient(self.mongodb_uri)
        self.db = self.mongo_client.ai_agents
        
        # ColecÈ›ii separate pentru fiecare agent sau global
        if agent_id:
            # ColecÈ›ii specifice pentru agent
            self.conversations_collection = self.db[f"qwen_conversations_{agent_id}"]
            self.learning_collection = self.db[f"qwen_learning_{agent_id}"]
            logger.info(f"âœ… Qwen Memory initialized for agent {agent_id}")
        else:
            # ColecÈ›ii globale (fallback)
            self.conversations_collection = self.db.qwen_conversations
            self.learning_collection = self.db.qwen_learning
        
    async def save_conversation(self, agent_id: str, user_message: str, qwen_response: str, context: Dict[str, Any] = None) -> bool:
        """SalveazÄƒ o conversaÈ›ie pentru Ã®nvÄƒÈ›are"""
        try:
            conversation = {
                "agent_id": agent_id,
                "timestamp": datetime.now(timezone.utc),
                "user_message": user_message,
                "qwen_response": qwen_response,
                "context": context or {},
                "learning_potential": self._assess_learning_potential(user_message, qwen_response)
            }
            
            result = self.conversations_collection.insert_one(conversation)
            logger.info(f"Saved conversation for agent {agent_id}: {result.inserted_id}")
            return True
            
        except Exception as e:
            logger.error(f"Error saving conversation: {e}")
            return False
    
    async def get_learning_context(self, agent_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """ObÈ›ine contextul de Ã®nvÄƒÈ›are pentru un agent"""
        try:
            conversations = list(self.conversations_collection.find(
                {"agent_id": agent_id},
                sort=[("timestamp", -1)],
                limit=limit
            ))
            
            # ConverteÈ™te ObjectId la string pentru JSON serialization
            for conv in conversations:
                conv["_id"] = str(conv["_id"])
                conv["timestamp"] = conv["timestamp"].isoformat()
            
            return conversations
            
        except Exception as e:
            logger.error(f"Error getting learning context: {e}")
            return []
    
    async def learn_from_conversations(self, agent_id: str) -> Dict[str, Any]:
        """Qwen Ã®nvaÈ›Äƒ din conversaÈ›iile anterioare"""
        try:
            # ObÈ›ine conversaÈ›iile recente
            conversations = await self.get_learning_context(agent_id, limit=20)
            
            if not conversations:
                return {
                    "status": "no_data",
                    "message": "No conversations to learn from",
                    "learned_patterns": []
                }
            
            # AnalizeazÄƒ pattern-urile de conversaÈ›ie
            patterns = self._analyze_conversation_patterns(conversations)
            
            # SalveazÄƒ pattern-urile Ã®nvÄƒÈ›ate
            learning_entry = {
                "agent_id": agent_id,
                "timestamp": datetime.now(timezone.utc),
                "patterns": patterns,
                "conversation_count": len(conversations),
                "learning_score": self._calculate_learning_score(patterns)
            }
            
            self.learning_collection.insert_one(learning_entry)
            
            return {
                "status": "success",
                "message": f"Learned from {len(conversations)} conversations",
                "learned_patterns": patterns,
                "learning_score": learning_entry["learning_score"]
            }
            
        except Exception as e:
            logger.error(f"Error in learning process: {e}")
            return {
                "status": "error",
                "message": str(e),
                "learned_patterns": []
            }
    
    async def get_enhanced_prompt(self, agent_id: str, base_prompt: str, user_message: str) -> str:
        """ÃmbunÄƒtÄƒÈ›eÈ™te prompt-ul cu contextul de Ã®nvÄƒÈ›are"""
        try:
            # ObÈ›ine contextul de Ã®nvÄƒÈ›are
            learning_context = await self.get_learning_context(agent_id, limit=5)
            
            if not learning_context:
                return base_prompt
            
            # ConstruieÈ™te contextul de Ã®nvÄƒÈ›are
            learning_summary = self._build_learning_summary(learning_context)
            
            # ÃmbunÄƒtÄƒÈ›eÈ™te prompt-ul
            enhanced_prompt = f"""
{base_prompt}

CONTEXT DE ÃNVÄ‚ÈšARE:
{learning_summary}

INSTRUCÈšIUNI PENTRU ÃNVÄ‚ÈšARE:
- FoloseÈ™te experienÈ›a din conversaÈ›iile anterioare pentru a rÄƒspunde mai bine
- AdapteazÄƒ stilul de rÄƒspuns la preferinÈ›ele utilizatorului
- MenÈ›ine consistenÈ›a cu rÄƒspunsurile anterioare
- ÃmbunÄƒtÄƒÈ›eÈ™te rÄƒspunsul pe baza feedback-ului implicit din conversaÈ›ii
"""
            
            return enhanced_prompt
            
        except Exception as e:
            logger.error(f"Error enhancing prompt: {e}")
            return base_prompt
    
    def _assess_learning_potential(self, user_message: str, qwen_response: str) -> float:
        """EvalueazÄƒ potenÈ›ialul de Ã®nvÄƒÈ›are al unei conversaÈ›ii"""
        score = 0.0
        
        # Factori care cresc potenÈ›ialul de Ã®nvÄƒÈ›are
        if len(user_message) > 50:  # Mesaje detaliate
            score += 0.2
        
        if len(qwen_response) > 100:  # RÄƒspunsuri detaliate
            score += 0.2
        
        if any(keyword in user_message.lower() for keyword in ['cum', 'ce', 'de ce', 'cÃ¢nd', 'unde']):
            score += 0.2  # ÃntrebÄƒri specifice
        
        if any(keyword in qwen_response.lower() for keyword in ['recomand', 'sugerez', 'pot sÄƒ', 'te ajut']):
            score += 0.2  # RÄƒspunsuri utile
        
        if 'tehnica-antifoc' in user_message.lower() or 'tehnica-antifoc' in qwen_response.lower():
            score += 0.2  # Context specific site
        
        return min(score, 1.0)
    
    def _analyze_conversation_patterns(self, conversations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """AnalizeazÄƒ pattern-urile din conversaÈ›ii"""
        patterns = {
            "common_questions": [],
            "response_styles": [],
            "user_preferences": [],
            "domain_specific_terms": []
        }
        
        # AnalizeazÄƒ Ã®ntrebÄƒrile comune
        questions = [conv["user_message"] for conv in conversations]
        common_words = {}
        for question in questions:
            words = question.lower().split()
            for word in words:
                if len(word) > 3:  # IgnorÄƒ cuvintele scurte
                    common_words[word] = common_words.get(word, 0) + 1
        
        patterns["common_questions"] = sorted(common_words.items(), key=lambda x: x[1], reverse=True)[:10]
        
        # AnalizeazÄƒ stilul de rÄƒspuns
        responses = [conv["qwen_response"] for conv in conversations]
        response_lengths = [len(resp) for resp in responses]
        patterns["response_styles"] = {
            "avg_length": sum(response_lengths) / len(response_lengths) if response_lengths else 0,
            "uses_emojis": sum(1 for resp in responses if any(emoji in resp for emoji in ['ğŸ”', 'ğŸ“‹', 'ğŸ’¡', 'ğŸ“', 'â­'])),
            "uses_formatting": sum(1 for resp in responses if '**' in resp or 'â€¢' in resp)
        }
        
        # AnalizeazÄƒ termenii specifici domeniului
        domain_terms = ['antifoc', 'protecÈ›ie', 'foc', 'matÄƒri', 'vopsea', 'termospumantÄƒ', 'certificare', 'isu']
        for term in domain_terms:
            count = sum(1 for conv in conversations if term in conv["user_message"].lower() or term in conv["qwen_response"].lower())
            if count > 0:
                patterns["domain_specific_terms"].append({"term": term, "frequency": count})
        
        return patterns
    
    def _calculate_learning_score(self, patterns: Dict[str, Any]) -> float:
        """CalculeazÄƒ scorul de Ã®nvÄƒÈ›are"""
        score = 0.0
        
        # Scor bazat pe Ã®ntrebÄƒrile comune
        if patterns["common_questions"]:
            score += 0.3
        
        # Scor bazat pe stilul de rÄƒspuns
        if patterns["response_styles"]["avg_length"] > 200:
            score += 0.2
        
        if patterns["response_styles"]["uses_emojis"] > 0:
            score += 0.2
        
        if patterns["response_styles"]["uses_formatting"] > 0:
            score += 0.2
        
        # Scor bazat pe termenii specifici
        if patterns["domain_specific_terms"]:
            score += 0.1
        
        return min(score, 1.0)
    
    def _build_learning_summary(self, conversations: List[Dict[str, Any]]) -> str:
        """ConstruieÈ™te un rezumat al Ã®nvÄƒÈ›Äƒrii"""
        if not conversations:
            return "Nu existÄƒ conversaÈ›ii anterioare pentru Ã®nvÄƒÈ›are."
        
        summary_parts = []
        
        # Rezumat al Ã®ntrebÄƒrilor recente
        recent_questions = [conv["user_message"][:100] + "..." if len(conv["user_message"]) > 100 else conv["user_message"] 
                          for conv in conversations[:3]]
        summary_parts.append(f"ÃntrebÄƒri recente: {'; '.join(recent_questions)}")
        
        # Rezumat al stilului de rÄƒspuns
        avg_length = sum(len(conv["qwen_response"]) for conv in conversations) / len(conversations)
        summary_parts.append(f"Lungimea medie a rÄƒspunsurilor: {int(avg_length)} caractere")
        
        # Rezumat al contextului specific
        domain_mentions = sum(1 for conv in conversations 
                            if any(term in conv["user_message"].lower() or term in conv["qwen_response"].lower() 
                                 for term in ['antifoc', 'protecÈ›ie', 'foc']))
        summary_parts.append(f"Context specific domeniu: {domain_mentions} menÈ›iuni")
        
        return "\n".join(summary_parts)

# FuncÈ›ie helper pentru a rula memoria
async def save_qwen_conversation(agent_id: str, user_message: str, qwen_response: str, context: Dict[str, Any] = None) -> bool:
    """SalveazÄƒ o conversaÈ›ie Qwen"""
    memory = QwenMemory()
    return await memory.save_conversation(agent_id, user_message, qwen_response, context)

async def get_qwen_learning_context(agent_id: str, limit: int = 10) -> List[Dict[str, Any]]:
    """ObÈ›ine contextul de Ã®nvÄƒÈ›are Qwen"""
    memory = QwenMemory()
    return await memory.get_learning_context(agent_id, limit)

if __name__ == "__main__":
    import asyncio
    
    async def test_memory():
        memory = QwenMemory()
        
        # TesteazÄƒ salvarea unei conversaÈ›ii
        success = await memory.save_conversation(
            "68e629bb5a7057c4b1b2f4da",
            "Ce produse oferiÈ›i?",
            "Oferim matÄƒri antifoc, vopsea termospumantÄƒ È™i uÈ™i rezistente la foc.",
            {"domain": "tehnica-antifoc.ro"}
        )
        print(f"Conversation saved: {success}")
        
        # TesteazÄƒ Ã®nvÄƒÈ›area
        learning_result = await memory.learn_from_conversations("68e629bb5a7057c4b1b2f4da")
        print(f"Learning result: {learning_result}")
    
    asyncio.run(test_memory())

