import requests
import json
from database.mongodb_handler import MongoDBHandler
import sys
import os
import openai
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from learning.continuous_learning_manager import ContinuousLearningManager

class ImprovedLearningAgent:
    def __init__(self, site_url):
        self.site_url = site_url
        self.vllm_url = "http://localhost:9301/v1/completions"
        self.mongodb = MongoDBHandler()
        self.learning_manager = ContinuousLearningManager()
        
        # ChatGPT cu prompt Ã®mbunÄƒtÄƒÈ›it
        self.openai_client = openai.OpenAI(
            api_key="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"
        )
        
    def get_site_context(self):
        return self.mongodb.get_site_content(self.site_url)
        
    def check_vllm_server(self):
        try:
            response = requests.get("http://localhost:9301/health", timeout=5)
            return response.status_code == 200
        except:
            return False
            
    def answer_with_chatgpt(self, question, context):
        """Prompt Ã®mbunÄƒtÄƒÈ›it pentru ChatGPT"""
        try:
            # Prompt mult mai specific È™i personalizat
            system_prompt = f"""EÈ™ti reprezentantul oficial al site-ului {context['title']}.

DESPRE COMPANIE:
{context['content'][:2000]}

INSTRUCÈšIUNI CRITICE:
1. RÄƒspunde DOAR ca È™i cum eÈ™ti site-ul Ã®nsuÈ™i - foloseÈ™te "noi", "oferim", "la noi"
2. BazeazÄƒ-te STRICT pe informaÈ›iile din conÈ›inutul site-ului
3. DacÄƒ Ã®ntrebarea nu se potriveÈ™te cu serviciile tale, explicÄƒ politicos ce faci TU
4. StructureazÄƒ rÄƒspunsul frumos cu bullet points
5. Fii specific despre serviciile tale, nu general
6. Maxim 150 cuvinte, profesional È™i prietenos

RÄƒspunde ca site-ul {self.site_url}:"""

            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question}
                ],
                max_tokens=200,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"Ne pare rÄƒu, avem o problemÄƒ tehnicÄƒ temporarÄƒ: {str(e)}"
        
    def answer_question_with_learning(self, question):
        context = self.get_site_context()
        if not context:
            return "Ne pare rÄƒu, nu avem Ã®ncÄƒ informaÈ›ii complete despre site."
            
        # ÃncearcÄƒ VLLM mai Ã®ntÃ¢i, apoi ChatGPT
        if self.check_vllm_server():
            print("ğŸš€ Folosesc VLLM (Qwen local)...")
            answer = self.answer_with_vllm(question, context)
        else:
            print("ğŸŒ Folosesc ChatGPT cu prompt Ã®mbunÄƒtÄƒÈ›it...")
            answer = self.answer_with_chatgpt(question, context)
        
        # SalveazÄƒ pentru Ã®nvÄƒÈ›are
        self.learning_manager.process_user_interaction(
            self.site_url, question, answer
        )
        
        return answer
        
    def answer_with_vllm(self, question, context):
        # Prompt Ã®mbunÄƒtÄƒÈ›it È™i pentru VLLM
        prompt = f"""Tu eÈ™ti site-ul {context['title']}.

Serviciile tale: {context['content'][:1000]}

Un vizitator Ã®ntreabÄƒ: {question}

RÄƒspunde ca site-ul Ã®nsuÈ™i, folosind "noi oferim", "la noi gÄƒsiÈ›i", etc.
BazeazÄƒ-te doar pe serviciile tale reale.
Maxim 100 cuvinte, structurat È™i profesional:"""

        payload = {
            "model": "Qwen/Qwen2.5-7B-Instruct",
            "prompt": prompt,
            "max_tokens": 150,
            "temperature": 0.2,
            "top_p": 0.9
        }
        
        try:
            response = requests.post(self.vllm_url, json=payload, timeout=20)
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['text'].strip()
            else:
                return "Avem o problemÄƒ tehnicÄƒ temporarÄƒ."
        except Exception as e:
            return f"Ne pare rÄƒu, sistem temporar indisponibil: {str(e)}"
            
    def provide_feedback(self, question, answer, feedback):
        self.learning_manager.process_user_interaction(
            self.site_url, question, answer, feedback
        )
        print(f"âœ… Feedback Ã®nregistrat: {feedback}")
