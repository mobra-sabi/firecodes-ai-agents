#!/usr/bin/env python3
"""
GPT-5 + Qwen 2.5 Architecture
ImplementeazƒÉ arhitectura completƒÉ conform specifica»õiilor:
- GPT-5: Orchestrator (planner/critic)
- Qwen 2.5: Executor (learning engine/site voice)
- Qdrant: Vector storage
- Brave API: Web search
"""

import asyncio
import json
import logging
import os
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
import requests
from openai import OpenAI
import aiohttp

logger = logging.getLogger(__name__)

@dataclass
class GPT5Plan:
    """Plan generat de GPT-5 (Orchestrator)"""
    mode: str  # "single_step" sau "plan"
    steps: List[Dict[str, Any]]
    guardrails: List[str]
    success_criteria: List[str]
    collection_priority: str  # "faq" sau "pages"

@dataclass
class QwenExecution:
    """Execu»õie realizatƒÉ de Qwen 2.5 (Learning Engine)"""
    answer: str
    sources: List[Dict[str, Any]]
    confidence: float
    tool_calls_used: int
    context_used: str

@dataclass
class GPT5Critique:
    """CriticƒÉ realizatƒÉ de GPT-5"""
    ok: bool
    issues: List[str]
    missing: List[str]
    suggestions: List[str]

class GPT5QwenArchitecture:
    """Arhitectura completƒÉ GPT-5 + Qwen 2.5"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
        # GPT-5 Client (Orchestrator)
        self.gpt5_client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url="https://api.openai.com/v1"
        )
        
        # Qwen 2.5 Client (Learning Engine)
        self.qwen_client = OpenAI(
            api_key="local",
            base_url=os.getenv("QWEN_BASE_URL", "http://localhost:11434/v1")
        )
        
        # Qdrant Client
        from qdrant_client import QdrantClient
        self.qdrant_client = QdrantClient(
            host=config.get("qdrant_host", "localhost"),
            port=config.get("qdrant_port", 9306)
        )
        
        # Brave API
        self.brave_api_key = os.getenv("BRAVE_API_KEY")
        
        # Configura»õii
        self.top_k = config.get("top_k", 6)
        self.confidence_threshold = config.get("confidence_threshold", 0.25)
        self.qwen_temperature = config.get("qwen_temperature", 0.2)
        
        logger.info("‚úÖ GPT-5 + Qwen 2.5 Architecture initialized")
    
    async def process_question(self, question: str, agent_id: str, site_url: str) -> Dict[str, Any]:
        """ProceseazƒÉ o √Æntrebare prin arhitectura completƒÉ"""
        start_time = time.time()
        
        try:
            # 1. Router - decide dacƒÉ e atomicƒÉ sau complexƒÉ
            router_decision = await self._router(question)
            logger.info(f"üîÄ Router decision: {router_decision}")
            
            if router_decision == "single_step":
                # Cale simplƒÉ: Qwen direct
                result = await self._single_step_execution(question, agent_id, site_url)
            else:
                # Cale complexƒÉ: GPT-5 plan + Qwen execu»õie + GPT-5 criticƒÉ
                result = await self._complex_execution(question, agent_id, site_url)
            
            # AdaugƒÉ metadata
            result["architecture"] = "gpt5_qwen_hybrid"
            result["processing_time"] = time.time() - start_time
            result["timestamp"] = datetime.now(timezone.utc).isoformat()
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error in GPT-5 + Qwen architecture: {e}")
            return {
                "ok": False,
                "error": str(e),
                "architecture": "gpt5_qwen_hybrid",
                "processing_time": time.time() - start_time
            }
    
    async def _router(self, question: str) -> str:
        """Router simplu - decide √Æntre single_step »ôi plan"""
        # Heuristici simple
        complex_keywords = [
            "comparƒÉ", "analizeazƒÉ", "evalueazƒÉ", "planificƒÉ", "strategie",
            "multiple", "diferite", "op»õiuni", "avantaje", "dezavantaje"
        ]
        
        question_lower = question.lower()
        if any(keyword in question_lower for keyword in complex_keywords):
            return "plan"
        
        # DacƒÉ e √Æntrebare atomicƒÉ
        return "single_step"
    
    async def _single_step_execution(self, question: str, agent_id: str, site_url: str) -> Dict[str, Any]:
        """Execu»õie simplƒÉ cu Qwen 2.5"""
        try:
            # 1. CƒÉutare √Æn Qdrant
            search_results = await self._search_qdrant(question, agent_id, "faq")
            if not search_results:
                search_results = await self._search_qdrant(question, agent_id, "pages")
            
            # 2. VerificƒÉ dacƒÉ trebuie web search
            web_results = []
            if self._needs_web_search(question):
                web_results = await self._web_search(question)
            
            # 3. Qwen 2.5 executƒÉ
            qwen_response = await self._qwen_execute(
                question=question,
                context=search_results,
                web_context=web_results,
                site_url=site_url,
                mode="single_step"
            )
            
            return {
                "ok": True,
                "response": qwen_response.answer,
                "confidence": qwen_response.confidence,
                "sources": qwen_response.sources,
                "web_search_used": len(web_results) > 0,
                "web_sources": web_results,
                "execution_mode": "single_step",
                "llm_used": "qwen2.5"
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error in single step execution: {e}")
            raise
    
    async def _complex_execution(self, question: str, agent_id: str, site_url: str) -> Dict[str, Any]:
        """Execu»õie complexƒÉ cu GPT-5 plan + Qwen execu»õie + GPT-5 criticƒÉ"""
        try:
            # 1. GPT-5 genereazƒÉ plan
            gpt5_plan = await self._gpt5_plan(question, site_url)
            logger.info(f"üìã GPT-5 Plan: {gpt5_plan.mode}")
            
            # 2. ExecutƒÉ planul cu Qwen 2.5
            qwen_execution = await self._execute_plan(gpt5_plan, question, agent_id, site_url)
            logger.info(f"‚ö° Qwen execution completed: {qwen_execution.confidence}")
            
            # 3. GPT-5 criticƒÉ rezultatul
            gpt5_critique = await self._gpt5_critique(
                question=question,
                draft=qwen_execution.answer,
                sources=qwen_execution.sources,
                plan=gpt5_plan
            )
            logger.info(f"üîç GPT-5 Critique: {gpt5_critique.ok}")
            
            # 4. DacƒÉ criticƒÉ nu e OK, reparƒÉ cu Qwen
            if not gpt5_critique.ok and gpt5_critique.suggestions:
                logger.info("üîß Repairing with Qwen based on GPT-5 critique")
                qwen_execution = await self._qwen_repair(
                    question=question,
                    original_answer=qwen_execution.answer,
                    critique=gpt5_critique,
                    context=qwen_execution.sources
                )
            
            return {
                "ok": True,
                "response": qwen_execution.answer,
                "confidence": qwen_execution.confidence,
                "sources": qwen_execution.sources,
                "execution_mode": "complex",
                "llm_used": "gpt5_qwen_hybrid",
                "plan": asdict(gpt5_plan),
                "critique": asdict(gpt5_critique),
                "web_search_used": False,  # TODO: implement √Æn plan
                "web_sources": []
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error in complex execution: {e}")
            raise
    
    async def _gpt5_plan(self, question: str, site_url: str) -> GPT5Plan:
        """GPT-5 genereazƒÉ plan de execu»õie"""
        domain = site_url.replace("https://", "").replace("http://", "").replace("www.", "")
        
        system_prompt = f"""E»ôti GPT-5, orchestratorul unui sistem AI hibrid. GenereazƒÉ un plan JSON pentru √Æntrebarea utilizatorului.

CONTEXT: Site-ul {domain}
√éNTREBARE: {question}

GenereazƒÉ un plan JSON cu aceastƒÉ structurƒÉ:
{{
    "mode": "single_step" sau "plan",
    "steps": [
        {{
            "step": 1,
            "action": "search_faq" sau "search_pages" sau "web_search" sau "analyze",
            "query": "query pentru cƒÉutare",
            "expected_output": "ce se a»ôteaptƒÉ"
        }}
    ],
    "guardrails": ["regula1", "regula2"],
    "success_criteria": ["criteriu1", "criteriu2"],
    "collection_priority": "faq" sau "pages"
}}

RƒÉspunde DOAR cu JSON valid, fƒÉrƒÉ text suplimentar."""

        try:
            response = self.gpt5_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "system", "content": system_prompt}],
                temperature=0.1,
                max_tokens=1000
            )
            
            plan_json = json.loads(response.choices[0].message.content)
            return GPT5Plan(**plan_json)
            
        except Exception as e:
            logger.error(f"‚ùå Error generating GPT-5 plan: {e}")
            # Fallback plan
            return GPT5Plan(
                mode="single_step",
                steps=[{"step": 1, "action": "search_pages", "query": question, "expected_output": "answer"}],
                guardrails=["be_accurate", "cite_sources"],
                success_criteria=["answer_question", "provide_sources"],
                collection_priority="pages"
            )
    
    async def _execute_plan(self, plan: GPT5Plan, question: str, agent_id: str, site_url: str) -> QwenExecution:
        """ExecutƒÉ planul cu Qwen 2.5"""
        context_parts = []
        sources = []
        
        # ExecutƒÉ fiecare pas din plan
        for step in plan.steps:
            if step["action"] == "search_faq":
                results = await self._search_qdrant(step["query"], agent_id, "faq")
                context_parts.extend([r["content"] for r in results])
                sources.extend(results)
            elif step["action"] == "search_pages":
                results = await self._search_qdrant(step["query"], agent_id, "pages")
                context_parts.extend([r["content"] for r in results])
                sources.extend(results)
            elif step["action"] == "web_search":
                results = await self._web_search(step["query"])
                context_parts.extend([r["description"] for r in results])
                sources.extend(results)
        
        # Qwen executƒÉ cu contextul
        return await self._qwen_execute(
            question=question,
            context=sources,
            web_context=[],
            site_url=site_url,
            mode="plan_execution"
        )
    
    async def _qwen_execute(self, question: str, context: List[Dict], web_context: List[Dict], site_url: str, mode: str) -> QwenExecution:
        """Qwen 2.5 executƒÉ √Æntrebarea"""
        domain = site_url.replace("https://", "").replace("http://", "").replace("www.", "")
        
        # PregƒÉte»ôte contextul
        context_text = "\n\n".join([
            f"**Sursa {i+1}:** {ctx.get('content', ctx.get('description', ''))}"
            for i, ctx in enumerate(context[:5])  # LimiteazƒÉ la 5 surse
        ])
        
        web_context_text = "\n\n".join([
            f"**Web {i+1}:** {web.get('title', '')} - {web.get('description', '')}"
            for i, web in enumerate(web_context[:3])  # LimiteazƒÉ la 3 surse web
        ])
        
        system_prompt = f"""E»ôti Qwen 2.5, learning engine-ul »ôi vocea site-ului {domain}.

ROL: Executor »ôi vocea site-ului
MOD: {mode}

CONTEXT SITE-ULUI:
{context_text}

CONTEXT WEB:
{web_context_text}

INSTRUC»öIUNI:
1. RƒÉspunde DOAR din contextul furnizat
2. DacƒÉ nu ai informa»õii suficiente, spui "Nu »ôtiu" + pa»ôi de verificare
3. Citezi sursele (minim 2 dacƒÉ existƒÉ)
4. Fii concis »ôi precis
5. Temperatura: {self.qwen_temperature} (QA precis)

FORMATARE:
- Folose»ôte emoji-uri: üîç üìã üí° üìû ‚≠ê ‚ùì
- Titluri bold: **Titlu**
- Bullet points: ‚Ä¢
- Spa»õiere √Æntre sec»õiuni

RƒÉspunde √Æn rom√¢nƒÉ, ca reprezentant oficial al {domain}."""

        try:
            response = self.qwen_client.chat.completions.create(
                model=os.getenv("QWEN_MODEL", "qwen:latest"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question}
                ],
                temperature=self.qwen_temperature,
                max_tokens=2000
            )
            
            answer = response.choices[0].message.content
            
            # CalculeazƒÉ confidence pe baza surselor
            confidence = min(0.9, 0.5 + (len(context) * 0.1))
            
            return QwenExecution(
                answer=answer,
                sources=context,
                confidence=confidence,
                tool_calls_used=len(context),
                context_used=context_text[:500] + "..." if len(context_text) > 500 else context_text
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error in Qwen execution: {e}")
            return QwenExecution(
                answer="√émi pare rƒÉu, nu pot rƒÉspunde √Æn acest moment. Te rog sƒÉ √Æncerci din nou.",
                sources=[],
                confidence=0.0,
                tool_calls_used=0,
                context_used=""
            )
    
    async def _gpt5_critique(self, question: str, draft: str, sources: List[Dict], plan: GPT5Plan) -> GPT5Critique:
        """GPT-5 criticƒÉ rƒÉspunsul generat de Qwen"""
        system_prompt = f"""E»ôti GPT-5, criticul sistemului AI hibrid. AnalizeazƒÉ rƒÉspunsul generat.

√éNTREBARE: {question}
RƒÇSPUNS GENERAT: {draft}
SURSE: {len(sources)} surse furnizate
PLAN: {plan.mode}

CriticƒÉ rƒÉspunsul »ôi returneazƒÉ JSON:
{{
    "ok": true/false,
    "issues": ["problema1", "problema2"],
    "missing": ["lipse»ôte1", "lipse»ôte2"],
    "suggestions": ["sugestie1", "sugestie2"]
}}

CRITERII:
1. RƒÉspunsul rƒÉspunde la √Æntrebare?
2. Sunt sursele citate corect?
3. Informa»õiile sunt accurate?
4. RƒÉspunsul este complet?
5. RespectƒÉ guardrails-urile: {plan.guardrails}

RƒÉspunde DOAR cu JSON valid."""

        try:
            response = self.gpt5_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "system", "content": system_prompt}],
                temperature=0.1,
                max_tokens=500
            )
            
            critique_json = json.loads(response.choices[0].message.content)
            return GPT5Critique(**critique_json)
            
        except Exception as e:
            logger.error(f"‚ùå Error in GPT-5 critique: {e}")
            return GPT5Critique(
                ok=True,
                issues=[],
                missing=[],
                suggestions=[]
            )
    
    async def _qwen_repair(self, question: str, original_answer: str, critique: GPT5Critique, context: List[Dict]) -> QwenExecution:
        """Qwen reparƒÉ rƒÉspunsul pe baza criticii GPT-5"""
        system_prompt = f"""E»ôti Qwen 2.5. ReparƒÉ rƒÉspunsul pe baza criticii GPT-5.

√éNTREBARE: {question}
RƒÇSPUNS ORIGINAL: {original_answer}

CRITICA GPT-5:
- OK: {critique.ok}
- Probleme: {critique.issues}
- Lipse»ôte: {critique.missing}
- Sugestii: {critique.suggestions}

CONTEXT: {len(context)} surse disponibile

GenereazƒÉ un rƒÉspuns √ÆmbunƒÉtƒÉ»õit care:
1. RezolvƒÉ problemele identificate
2. AdaugƒÉ informa»õiile lipsƒÉ
3. UrmeazƒÉ sugestiile
4. Men»õine acurate»õea »ôi citarea surselor

RƒÉspunde √Æn rom√¢nƒÉ, formatat frumos cu emoji-uri."""

        try:
            response = self.qwen_client.chat.completions.create(
                model=os.getenv("QWEN_MODEL", "qwen:latest"),
                messages=[{"role": "system", "content": system_prompt}],
                temperature=0.3,  # Pu»õin mai creativ pentru reparare
                max_tokens=2000
            )
            
            repaired_answer = response.choices[0].message.content
            
            return QwenExecution(
                answer=repaired_answer,
                sources=context,
                confidence=0.8,  # Confidence mai mare dupƒÉ reparare
                tool_calls_used=len(context),
                context_used="repaired"
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error in Qwen repair: {e}")
            return QwenExecution(
                answer=original_answer,  # ReturneazƒÉ originalul dacƒÉ repararea e»ôueazƒÉ
                sources=context,
                confidence=0.5,
                tool_calls_used=len(context),
                context_used="repair_failed"
            )
    
    async def _search_qdrant(self, query: str, agent_id: str, collection_type: str) -> List[Dict[str, Any]]:
        """CautƒÉ √Æn Qdrant"""
        try:
            collection_name = f"agent_{agent_id}_{collection_type}"
            
            # GenereazƒÉ embedding pentru query
            embedding = await self._generate_embedding(query)
            
            # CautƒÉ √Æn Qdrant
            results = self.qdrant_client.search(
                collection_name=collection_name,
                query_vector=embedding,
                limit=self.top_k,
                score_threshold=self.confidence_threshold
            )
            
            return [
                {
                    "content": result.payload.get("content", ""),
                    "url": result.payload.get("url", ""),
                    "title": result.payload.get("title", ""),
                    "score": result.score
                }
                for result in results
            ]
            
        except Exception as e:
            logger.error(f"‚ùå Error searching Qdrant: {e}")
            return []
    
    async def _generate_embedding(self, text: str) -> List[float]:
        """GenereazƒÉ embedding pentru text"""
        try:
            # Folose»ôte OpenAI embeddings
            response = self.gpt5_client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"‚ùå Error generating embedding: {e}")
            return [0.0] * 1536  # Fallback
    
    async def _web_search(self, query: str) -> List[Dict[str, str]]:
        """CautƒÉ pe internet cu Brave API"""
        if not self.brave_api_key:
            return []
        
        try:
            headers = {
                "Accept": "application/json",
                "X-Subscription-Token": self.brave_api_key
            }
            
            params = {"q": query, "count": 3}
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    "https://api.search.brave.com/res/v1/web/search",
                    headers=headers,
                    params=params,
                    timeout=10
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = []
                        
                        if "web" in data and "results" in data["web"]:
                            for result in data["web"]["results"]:
                                results.append({
                                    "title": result.get("title", ""),
                                    "url": result.get("url", ""),
                                    "description": result.get("description", ""),
                                    "age": result.get("age", "")
                                })
                        
                        return results
                    else:
                        logger.error(f"‚ùå Brave API error: {response.status}")
                        return []
                        
        except Exception as e:
            logger.error(f"‚ùå Error in web search: {e}")
            return []
    
    def _needs_web_search(self, question: str) -> bool:
        """Decide dacƒÉ √Æntrebarea necesitƒÉ web search"""
        web_keywords = [
            "pre»õ", "pre»õuri", "cost", "actual", "curent", "ultim", "nou",
            "comparƒÉ", "diferen»õƒÉ", "op»õiuni", "alternativ"
        ]
        
        question_lower = question.lower()
        return any(keyword in question_lower for keyword in web_keywords)

# Func»õie de utilitate pentru crearea arhitecturii
def create_gpt5_qwen_architecture(config: Dict[str, Any] = None) -> GPT5QwenArchitecture:
    """CreeazƒÉ instan»õa arhitecturii GPT-5 + Qwen 2.5"""
    if config is None:
        config = {
            "qdrant_host": "localhost",
            "qdrant_port": 9306,
            "top_k": 6,
            "confidence_threshold": 0.25,
            "qwen_temperature": 0.2
        }
    
    return GPT5QwenArchitecture(config)

if __name__ == "__main__":
    async def test_architecture():
        architecture = create_gpt5_qwen_architecture()
        
        result = await architecture.process_question(
            question="Ce servicii oferi»õi?",
            agent_id="test_agent",
            site_url="https://protectiilafoc.ro"
        )
        
        print("üîç Test Result:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    asyncio.run(test_architecture())
