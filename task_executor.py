import os
import json
import asyncio
import logging
import requests
from typing import List

from starlette.websockets import WebSocketDisconnect
from pydantic import BaseModel, Field

from langchain_openai import ChatOpenAI
# from langchain.agents.factory import create_agent  # Deprecated in langchain 1.0+
from langchain_core.tools import StructuredTool

from agent_tools import get_tools_for_agent
from pymongo import MongoClient
from llm_orchestrator import get_orchestrator

# Compat pentru excepÈ›ia de parsing (diferenÈ›e Ã®ntre versiuni LangChain)
try:
    from langchain_core.exceptions import OutputParserException
except Exception:
    try:
        from langchain.schema.output_parser import OutputParserException  # older
    except Exception:
        class OutputParserException(Exception):
            pass

# Mesaje pentru fallback direct pe LLM
try:
    from langchain_core.messages import SystemMessage, HumanMessage
except Exception:
    SystemMessage = None
    HumanMessage = None

logger = logging.getLogger("task_executor")

MONGO_URI = os.getenv("MONGO_URI", "mongodb://localhost:9308/")
mongo_client = MongoClient(MONGO_URI)
db = mongo_client.ai_agents_db


async def send_ws_message(websocket, type_, data):
    await websocket.send_json({"type": type_, "data": data})


async def send_status(ws, text: str):
    try:
        await ws.send_json({"type": "status", "data": text})
    except Exception:
        # dacÄƒ socketul e Ã®nchis, ignorÄƒm
        pass


class DiscoverInput(BaseModel):
    limit: int = Field(10, ge=1, le=50, description="CÃ¢te rezultate sÄƒ Ã®ncerce sÄƒ gÄƒseascÄƒ")


class IngestInput(BaseModel):
    urls: List[str] = Field(..., description="Lista de URL-uri de ingerat ca agenÈ›i")
    max_pages: int = Field(3, ge=1, le=50, description="NumÄƒr maxim de pagini de scanat per site")


def make_discover_tool(agent_id: str, base_url: str, ws, loop):
    def _run(limit: int = 10) -> str:
        try:
            asyncio.run_coroutine_threadsafe(send_status(ws, f"ğŸ” Discover start (limit={limit})"), loop)
        except Exception:
            pass
        try:
            r = requests.post(
                f"{base_url}/admin/industry/{agent_id}/discover",
                json={"limit": int(limit)},
                timeout=300,
            )
            r.raise_for_status()
            data = r.json()
            try:
                asyncio.run_coroutine_threadsafe(
                    send_status(ws, f"ğŸ” Discover done: {data.get('count', 0)} candidaÈ›i"),
                    loop,
                )
            except Exception:
                pass
            return json.dumps(
                {"ok": True, "results": data.get("results", []), "queries": data.get("queries", [])},
                ensure_ascii=False,
            )
        except Exception as e:
            try:
                asyncio.run_coroutine_threadsafe(send_status(ws, f"â— Discover error: {e}"), loop)
            except Exception:
                pass
            return json.dumps({"ok": False, "error": str(e)}, ensure_ascii=False)

    return StructuredTool.from_function(
        name="discover_industry",
        description=(
            "DescoperÄƒ competitori pentru site-ul curent. ReturneazÄƒ candidaÈ›i {url, score, reason}. "
            "FoloseÈ™te cÃ¢nd vrei extindere de cunoaÈ™tere."
        ),
        func=_run,
        args_schema=DiscoverInput,
        return_direct=False,
    )


def make_ingest_tool(agent_id: str, base_url: str, ws, loop):
    def _run(urls: List[str], max_pages: int = 3) -> str:
        try:
            asyncio.run_coroutine_threadsafe(
                send_status(ws, f"ğŸ“¥ Ingest start ({len(urls)} URL-uri, max_pages={max_pages})"),
                loop,
            )
        except Exception:
            pass
        try:
            r = requests.post(
                f"{base_url}/admin/industry/{agent_id}/ingest",
                json={"urls": urls, "max_pages": int(max_pages)},
                timeout=900,
            )
            r.raise_for_status()
            data = r.json()
            try:
                asyncio.run_coroutine_threadsafe(
                    send_status(ws, f"ğŸ“¥ Ingest done: {data.get('created_count', 0)} agenÈ›i creaÈ›i"),
                    loop,
                )
            except Exception:
                pass
            return json.dumps(
                {"ok": True, "created": data.get("created", []), "created_count": data.get("created_count", 0)},
                ensure_ascii=False,
            )
        except Exception as e:
            try:
                asyncio.run_coroutine_threadsafe(send_status(ws, f"â— Ingest error: {e}"), loop)
            except Exception:
                pass
            return json.dumps({"ok": False, "error": str(e)}, ensure_ascii=False)

    return StructuredTool.from_function(
        name="ingest_sites",
        description=(
            "IngereazÄƒ URL-uri ca agenÈ›i noi (creeazÄƒ agenÈ›i È™i scaneazÄƒ pagini). "
            "FoloseÈ™te dupÄƒ discover pentru top 2â€“3 URL-uri."
        ),
        func=_run,
        args_schema=IngestInput,
        return_direct=False,
    )


async def handle_task_conversation(websocket, api_key: str, agent_id: str, site_url: str, initial_strategy: str):
    await send_status(websocket, "IniÈ›ializez agentul cu unelte...")

    # LLM: temperaturÄƒ micÄƒ, stabil
    llm = ChatOpenAI(
        model_name=os.getenv("LLM_MODEL", "gpt-4o-mini"),
        openai_api_key=api_key,
        temperature=0,
    )

    # Unelte de bazÄƒ pentru agent (ex. RAG/retriever pentru site)
    base_tools = get_tools_for_agent(agent_id) or []

    # Unelte Admin expuse conversaÈ›iei (discover + ingest)
    loop = asyncio.get_running_loop()
    BASE_URL = os.getenv("AGENT_API_BASE_URL", "http://127.0.0.1:8083")
    discover_tool = make_discover_tool(agent_id, BASE_URL, websocket, loop)
    ingest_tool = make_ingest_tool(agent_id, BASE_URL, websocket, loop)

    tools = [discover_tool, ingest_tool] + list(base_tools)

    # InstructÄƒm ferm agentul sÄƒ NU halucineze È™i sÄƒ foloseascÄƒ Ã®ntÃ¢i uneltele
    SAFETY_INSTRUCTIONS = (
        "InstrucÈ›iuni generale (respectÄƒ-le Ã®n orice rÄƒspuns): "
        "1) RÄƒspunde EXCLUSIV Ã®n limba romÃ¢nÄƒ, concis È™i direct. "
        f"2) FoloseÈ™te DOAR informaÈ›ii din site-ul curent ({site_url}); dacÄƒ informaÈ›ia nu e Ã®ncÄƒ disponibilÄƒ, "
        "trebuie sÄƒ foloseÈ™ti uneltele (tools) pentru a cÄƒuta/recupera conÈ›inutul relevant. "
        "3) NU inventa produse/denumiri; dacÄƒ nu ai dovezi din conÈ›inut, spune explicit ce Ã®È›i lipseÈ™te È™i cere sÄƒ scanezi/apelezi uneltele. "
        "4) Pentru extindere: "
        "   - ApeleazÄƒ mai Ã®ntÃ¢i discover_industry(limit=8..12). "
        "   - SelecteazÄƒ 2â€“3 URL-uri cu scor mare È™i apeleazÄƒ ingest_sites(urls=[...], max_pages=3). "
        "   - ExplicÄƒ pe scurt ce ai creat. "
        "5) CÃ¢nd finalizezi, oferÄƒ un rÄƒspuns clar pentru utilizator."
    )

    # 1) ÃncarcÄƒ contextul agentului + rezumat scurt pentru LLM
    try:
        agent_doc = db.agents.find_one({"_id": __import__("bson").ObjectId(agent_id)})
    except Exception:
        agent_doc = None
    summary_lines = []
    if agent_doc:
        summary_lines.append(f"Agent: {agent_doc.get('name') or ''} domain={agent_doc.get('domain') or ''} site_url={agent_doc.get('site_url') or ''}")
        # extrage cÃ¢teva bucÄƒÈ›i de conÈ›inut din vector store, dacÄƒ existÄƒ tool search_site
        try:
            if base_tools:
                snippet = ""  # pÄƒstrÄƒm loc pentru viitoare extrageri din RAG
                if snippet:
                    summary_lines.append(f"Snippet: {snippet[:400]}")
        except Exception:
            pass
    context_summary = "\n".join([s for s in summary_lines if s])

    # 2) Propunere iniÈ›ialÄƒ de strategie afiÈ™atÄƒ Ã®n chat
    proposal_prompt = (
        "EÈ™ti un orchestrator. PrimeÈ™ti un website È™i trebuie sÄƒ propui direcÈ›ii de cÄƒutare È™i Ã®nÈ›elegere a industriei.\n"
        f"Website: {site_url}\n"
        f"Context agent (din DB):\n{context_summary}\n\n"
        "Propune 3-5 direcÈ›ii concrete (puncte) care includ: interogÄƒri SERP, tipuri de pagini de analizat, competitori probabili, È™i ce metrici sÄƒ colectÄƒm. RÄƒspuns scurt, Ã®n romÃ¢nÄƒ."
    )
    try:
        proposal = await llm.ainvoke(proposal_prompt) if hasattr(llm, "ainvoke") else await asyncio.to_thread(llm.invoke, proposal_prompt)
        proposal_text = getattr(proposal, "content", str(proposal))
    except Exception:
        proposal_text = "(nu am reuÈ™it sÄƒ generez o propunere acum)"

    await send_ws_message(websocket, "assistant", f"Propunere iniÈ›ialÄƒ de strategie:\n{proposal_text}")

    # Agent cu function calling (mai robust decÃ¢t parsere text)
    # agent_graph = create_agent(  # Deprecated in langchain 1.0+
    #     model=llm,
    #     tools=tools,
    #     system_prompt=SAFETY_INSTRUCTIONS,
    #     debug=True,
    # )
    agent_graph = None  # TODO: replace with langchain 1.0+ agent creation

    # Mesaj de Ã®ntÃ¢mpinare Ã®n romÃ¢nÄƒ
    greeting = f"BunÄƒ! Sunt consilierul pentru {site_url}. Cu ce te pot ajuta Ã®n strategia â€{initial_strategy}â€?"
    await send_status(websocket, f"Agent pregÄƒtit pentru {site_url}.")
    await send_status(websocket, "Unelte active: discover_industry, ingest_sites")
    await send_ws_message(websocket, "assistant", greeting)

    # Sistem/fallback pentru rÄƒspuns direct fÄƒrÄƒ unelte (Ã®n caz de erori interne)
    SAFE_SYS = (
        "Vei rÄƒspunde EXCLUSIV Ã®n limba romÃ¢nÄƒ, concis, util È™i fÄƒrÄƒ preambuluri despre faptul cÄƒ eÈ™ti un AI. "
        "FoloseÈ™te DOAR informaÈ›ii din site-ul curent. DacÄƒ nu le ai, spune ce Ã®È›i lipseÈ™te È™i cere permisiunea sÄƒ scanezi/apelezi uneltele."
    )

    try:
        while True:
            try:
                user_message = await websocket.receive_text()
            except WebSocketDisconnect:
                logger.info("WebSocket closed by client")
                return

            await send_ws_message(websocket, "user", user_message)

            guided_input = f"{SAFETY_INSTRUCTIONS}\n\nÃntrebare utilizator: {user_message}"

            try:
                # ruleazÄƒ sincron Ã®ntr-un thread, pentru a nu bloca event loop-ul
                from langchain_core.messages import HumanMessage
                messages = [HumanMessage(content=guided_input)]
                if agent_graph:
                    result = await asyncio.to_thread(agent_graph.invoke, {"messages": messages})
                else:
                    # Fallback direct pe LLM dacÄƒ agent_graph nu e disponibil
                    result = await llm.ainvoke(messages) if hasattr(llm, "ainvoke") else await asyncio.to_thread(llm.invoke, messages)
                    result = {"messages": [result]} if not isinstance(result, dict) else result
                
                # Extrage ultimul mesaj AI din rezultat
                if isinstance(result, dict) and "messages" in result:
                    messages = result["messages"]
                    ai_text = ""
                    for msg in reversed(messages):
                        if hasattr(msg, "content") and msg.content and not hasattr(msg, "tool_calls"):
                            ai_text = msg.content
                            break
                else:
                    ai_text = str(result) if result else ""
                
                if not ai_text:
                    ai_text = "Nu am reuÈ™it sÄƒ generez un rÄƒspuns util pe baza conÈ›inutului disponibil."
                await send_ws_message(websocket, "assistant", ai_text)

            except OutputParserException:
                # Fallback: rÄƒspuns direct pe LLM (fÄƒrÄƒ tooluri), Ã®n romÃ¢nÄƒ
                logger.warning("OutputParserException - fallback direct pe LLM.")
                if hasattr(llm, "ainvoke"):
                    if SystemMessage and HumanMessage:
                        msg = await llm.ainvoke([SystemMessage(content=SAFE_SYS), HumanMessage(content=user_message)])
                        ai_text = getattr(msg, "content", str(msg))
                    else:
                        ai_text = (await llm.ainvoke(f"{SAFE_SYS}\n\nÃntrebare: {user_message}")).content
                else:
                    def _call_llm():
                        if SystemMessage and HumanMessage:
                            m = llm.invoke([SystemMessage(content=SAFE_SYS), HumanMessage(content=user_message)])
                            return getattr(m, "content", str(m))
                        return llm.invoke(f"{SAFE_SYS}\n\nÃntrebare: {user_message}").content
                    ai_text = await asyncio.to_thread(_call_llm)

                await send_ws_message(websocket, "assistant", ai_text)

            except WebSocketDisconnect:
                logger.info("WebSocket closed by client")
                return

            except Exception as e:
                logger.exception("Eroare agent:")
                try:
                    await send_ws_message(
                        websocket, "error",
                        f"Eroare Ã®n agent: {e}. DacÄƒ problema persistÄƒ, Ã®ncearcÄƒ din nou sau cere scanarea paginilor relevante."
                    )
                except Exception:
                    # WS poate fi deja Ã®nchis
                    pass

    except Exception as e:
        logger.info(f"Conexiune WS Ã®nchisÄƒ sau altÄƒ eroare: {e}")
        try:
            await send_ws_message(websocket, "error", str(e))
        except Exception:
            pass
