import logging
from typing import List, Dict, Any
from llm_orchestrator import get_orchestrator
from pymongo import MongoClient
import os
import psutil
import json

logger = logging.getLogger(__name__)

class SystemController:
    def __init__(self):
        self.llm = get_orchestrator()
        self.mongo_client = MongoClient(os.getenv("MONGODB_URI", "mongodb://localhost:27018/"))
        self.db = self.mongo_client["ai_agents_db"]

    def get_system_status(self) -> str:
        """ColecteazÄƒ statusul live al sistemului pentru a-l da AI-ului"""
        
        # 1. Hardware
        cpu_percent = psutil.cpu_percent()
        ram_percent = psutil.virtual_memory().percent
        
        # 2. Database Stats
        agents_count = self.db.site_agents.count_documents({})
        competitors_count = self.db.site_agents.count_documents({"agent_type": "slave"})
        
        # 3. Running Processes (Simplificat)
        # VerificÄƒm dacÄƒ ruleazÄƒ workflow-ul
        workflow_running = False
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if 'python' in proc.info['name'] and proc.info['cmdline'] and 'ceo_master_workflow.py' in ' '.join(proc.info['cmdline']):
                    workflow_running = True
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
                
        status = f"""
STATUS SISTEM:
- Hardware: CPU {cpu_percent}%, RAM {ram_percent}%
- BazÄƒ de Date: {agents_count} agenÈ›i totali ({competitors_count} competitori)
- Procese Active: {'âœ… CEO Workflow (Scraping/Validare)' if workflow_running else 'ğŸ’¤ Idle'}
- LLM: Qwen 2.5 72B (Local - 8 GPUs)
"""
        return status

    def process_user_message(self, user_message: str) -> Dict[str, Any]:
        """ProceseazÄƒ mesajul utilizatorului È™i decide acÈ›iunea"""
        
        system_status = self.get_system_status()
        
        # System Prompt care defineÈ™te personalitatea de "Controller"
        system_prompt = f"""EÈ™ti AI COMMANDER, interfaÈ›a centralÄƒ de control pentru un sistem complex de Business Intelligence.
        
{system_status}

ROLUL TÄ‚U:
1. SÄƒ rÄƒspunzi la Ã®ntrebÄƒrile utilizatorului despre statusul sistemului.
2. SÄƒ propui acÈ›iuni concrete pe care utilizatorul le poate confirma.
3. SÄƒ fii concis, profesional È™i strategic.

CAPACITÄ‚ÈšI (TOOLS) PE CARE LE POÈšI PROPUNE (Ã®n JSON):
- "start_scan": Pentru a Ã®ncepe o analizÄƒ nouÄƒ.
- "stop_scan": Pentru a opri procesele curente.
- "generate_report": Pentru a genera rapoarte PDF/Markdown.
- "show_competitors": Pentru a afiÈ™a lista competitorilor.

DacÄƒ utilizatorul cere ceva ce necesitÄƒ o acÈ›iune, RÄ‚SPUNDE ÃN FORMAT JSON astfel:
{{
    "text": "Textul tÄƒu explicativ aici...",
    "suggested_actions": [
        {{"label": "Nume Buton 1", "action": "nume_actiune", "params": {{...}}}},
        {{"label": "Nume Buton 2", "action": "nume_actiune", "params": {{...}}}}
    ]
}}

DacÄƒ e doar o discuÈ›ie, rÄƒspunde cu JSON doar cu cÃ¢mpul "text".
NU folosi markdown code blocks pentru JSON. ReturneazÄƒ JSON pur.
"""

        try:
            response = self.llm.chat(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            # ÃncercÄƒm sÄƒ parsÄƒm JSON-ul generat de AI
            content = response if isinstance(response, str) else response.get("content", "")
            
            # CurÄƒÈ›are basic
            content = content.strip()
            if content.startswith("```json"): content = content[7:]
            if content.startswith("```"): content = content[3:]
            if content.endswith("```"): content = content[:-3]
            
            try:
                data = json.loads(content)
                return data
            except json.JSONDecodeError:
                # DacÄƒ AI-ul nu a returnat JSON (s-a "prostit"), Ã®l Ã®mpachetÄƒm noi
                return {"text": content, "suggested_actions": []}
                
        except Exception as e:
            logger.error(f"Chat Controller Error: {e}")
            return {"text": f"Eroare de sistem: {str(e)}", "suggested_actions": []}

# Singleton
_controller = None
def get_controller():
    global _controller
    if _controller is None:
        _controller = SystemController()
    return _controller

