"""
ğŸ—ï¸ Industry Mass Agent Creator - ConstrucÈ›ii RomÃ¢nia
=====================================================

Sistem pentru transformarea Ã®ntregii industrii de construcÈ›ii din RomÃ¢nia
Ã®n agenÈ›i AI compleÈ›i, cu DeepSeek ca orchestrator principal.
"""

import asyncio
import logging
import traceback
from typing import List, Dict, Optional
from datetime import datetime, timezone, timedelta
from pymongo import MongoClient
from bson import ObjectId
from llm_orchestrator import LLMOrchestrator
from ceo_master_workflow import CEOMasterWorkflow
from industry_transformation_logger import IndustryTransformationLogger

logger = logging.getLogger(__name__)


class ConstructionIndustryDiscovery:
    """DescoperÄƒ companii din industria de construcÈ›ii din RomÃ¢nia"""
    
    def __init__(self, mongo_client: MongoClient, llm: LLMOrchestrator, transformation_logger=None):
        self.mongo = mongo_client
        self.db = mongo_client["ai_agents_db"]
        self.llm = llm
        self.logger = transformation_logger
        
        # Collection pentru companii descoperite
        self.discovered_companies_collection = self.db["construction_companies_discovered"]
        
        logger.info("âœ… Construction Industry Discovery initialized")
    
    async def discover_companies_via_deepseek(self, max_companies: int = 500, session_id: str = None) -> List[Dict]:
        """
        FoloseÈ™te DeepSeek pentru a descoperi companii din construcÈ›ii
        
        DeepSeek genereazÄƒ o listÄƒ de companii relevante din RomÃ¢nia
        
        Args:
            max_companies: NumÄƒrul maxim de companii de descoperit
            progress_callback: FuncÈ›ie callback pentru progres (opÈ›ional)
        """
        try:
            logger.info(f"ğŸ” Discovering construction companies via DeepSeek (max: {max_companies})")
            
            if self.logger and session_id:
                self.logger.log(session_id, "deepseek_discovery", f"ğŸ” Ãncep descoperirea a {max_companies} companii via DeepSeek...")
            
            # Log cÄƒ Ã®ncepem apelul REAL la DeepSeek
            logger.info(f"ğŸ“ Calling REAL DeepSeek API for {max_companies} companies...")
            
            prompt = f"""EÈ™ti un expert Ã®n industria de construcÈ›ii din RomÃ¢nia.

IMPORTANT: ReturneazÄƒ DOAR JSON valid, fÄƒrÄƒ markdown, fÄƒrÄƒ explicaÈ›ii, fÄƒrÄƒ text Ã®nainte sau dupÄƒ JSON.

GenerazÄƒ o listÄƒ JSON cu {max_companies} de companii importante din industria de construcÈ›ii din RomÃ¢nia.

Fiecare companie trebuie sÄƒ aibÄƒ:
- nume_companie: numele complet
- domeniu: domeniul website-ului (ex: companie.ro)
- activitate: tipul de activitate (ex: "ConstrucÈ›ii civile", "InstalaÈ›ii", "Proiectare")
- oras: oraÈ™ul principal
- descriere_scurta: 1-2 propoziÈ›ii despre companie

Format JSON EXACT (fÄƒrÄƒ markdown, fÄƒrÄƒ ```json):
{{
  "companii": [
    {{
      "nume_companie": "...",
      "domeniu": "...",
      "activitate": "...",
      "oras": "...",
      "descriere_scurta": "..."
    }}
  ]
}}

REGLI STRICTE:
1. Ãncepe direct cu {{ (fÄƒrÄƒ text Ã®nainte)
2. TerminÄƒ cu }} (fÄƒrÄƒ text dupÄƒ)
3. FÄƒrÄƒ markdown code blocks (```json sau ```)
4. FÄƒrÄƒ explicaÈ›ii sau comentarii
5. JSON valid È™i complet

ReturneazÄƒ DOAR JSON-ul de mai sus, nimic altceva."""

            # Apel REAL la DeepSeek API
            logger.info(f"ğŸ“ Making REAL API call to DeepSeek...")
            response = self.llm.chat(
                messages=[{"role": "user", "content": prompt}],
                model="deepseek-chat",
                temperature=0.7,
                max_tokens=8000
            )
            
            # Log rÄƒspunsul primit
            logger.info(f"ğŸ“¥ DeepSeek API response received (type: {type(response)}, length: {len(str(response))})")
            
            # ParseazÄƒ rÄƒspunsul
            if isinstance(response, dict):
                response_text = response.get("content", str(response))
            else:
                response_text = str(response)
            
            # Log primele 500 caractere pentru debugging
            logger.info(f"ğŸ“„ Response preview (first 500 chars): {response_text[:500]}")
            
            if self.logger and session_id:
                self.logger.log(
                    session_id,
                    "deepseek_discovery",
                    f"ğŸ“¥ RÄƒspuns REAL DeepSeek primit ({len(response_text)} caractere). Ãncep parsing JSON...",
                    {"response_length": len(response_text), "response_preview": response_text[:200]}
                )
            
            # Extrage JSON din rÄƒspuns
            import json
            import re
            
            companies = []
            
            # ÃncearcÄƒ mai multe metode de parsing
            parse_success = False
            companies = []
            
            # Metoda 1: ParseazÄƒ Ã®ntregul rÄƒspuns ca JSON
            try:
                data = json.loads(response_text)
                companies = data.get("companii", [])
                if companies:
                    logger.info(f"âœ… Metoda 1 SUCCESS: Parsed JSON directly - {len(companies)} companies")
                    parse_success = True
                    if self.logger and session_id:
                        self.logger.log(
                            session_id,
                            "deepseek_discovery",
                            f"âœ… JSON parsat cu succes (metoda 1): {len(companies)} companii gÄƒsite",
                            {"parsing_method": "direct", "companies_count": len(companies)}
                        )
            except Exception as e1:
                logger.warning(f"âš ï¸ Metoda 1 failed: {e1}")
            
            # Metoda 2: EliminÄƒ markdown È™i cautÄƒ JSON
            if not parse_success:
                try:
                    cleaned_text = re.sub(r'```json\s*', '', response_text)
                    cleaned_text = re.sub(r'```\s*', '', cleaned_text)
                    cleaned_text = re.sub(r'^[^{]*', '', cleaned_text)  # EliminÄƒ text Ã®nainte de {
                    cleaned_text = re.sub(r'[^}]*$', '', cleaned_text)  # EliminÄƒ text dupÄƒ }
                    
                    if self.logger and session_id:
                        self.logger.log(
                            session_id,
                            "deepseek_discovery",
                            f"ğŸ”„ ÃncearcÄƒ metoda 2: eliminare markdown È™i regex...",
                            {"cleaned_length": len(cleaned_text)}
                        )
                    
                    # CautÄƒ JSON object care conÈ›ine "companii"
                    json_match = re.search(r'\{[^{]*"companii"\s*:\s*\[[^\]]*\][^}]*\}', cleaned_text, re.DOTALL)
                    if not json_match:
                        # ÃncearcÄƒ un JSON mai mare care poate conÈ›ine mai multe obiecte
                        json_match = re.search(r'\{.*?"companii".*?\}', cleaned_text, re.DOTALL)
                    
                    if json_match:
                        json_str = json_match.group(0)
                        # ÃncearcÄƒ sÄƒ gÄƒseascÄƒ sfÃ¢rÈ™itul corect al JSON-ului
                        brace_count = 0
                        end_pos = 0
                        for i, char in enumerate(json_str):
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    end_pos = i + 1
                                    break
                        if end_pos > 0:
                            json_str = json_str[:end_pos]
                        
                        data = json.loads(json_str)
                        companies = data.get("companii", [])
                        if companies:
                            logger.info(f"âœ… Metoda 2 SUCCESS: Parsed JSON from regex - {len(companies)} companies")
                            parse_success = True
                            if self.logger and session_id:
                                self.logger.log(
                                    session_id,
                                    "deepseek_discovery",
                                    f"âœ… JSON parsat cu succes (metoda 2): {len(companies)} companii gÄƒsite",
                                    {"parsing_method": "regex_with_companii", "companies_count": len(companies)}
                                )
                except Exception as e2:
                    logger.warning(f"âš ï¸ Metoda 2 failed: {e2}")
            
            # Metoda 3: CautÄƒ array-ul de companii direct (mai robust)
            if not parse_success:
                try:
                    # CautÄƒ direct array-ul "companii" cu pattern mai robust
                    # GÄƒseÈ™te "companii": [ ... ] inclusiv cu nested objects
                    pattern = r'"companii"\s*:\s*\['
                    start_match = re.search(pattern, response_text)
                    if start_match:
                        start_pos = start_match.end()
                        # GÄƒseÈ™te sfÃ¢rÈ™itul array-ului (ultimul ] care Ã®nchide array-ul)
                        bracket_count = 1
                        end_pos = start_pos
                        i = start_pos
                        while i < len(response_text) and bracket_count > 0:
                            if response_text[i] == '[':
                                bracket_count += 1
                            elif response_text[i] == ']':
                                bracket_count -= 1
                                if bracket_count == 0:
                                    end_pos = i
                                    break
                            i += 1
                        
                        if end_pos > start_pos:
                            array_content = response_text[start_pos:end_pos]
                            # ParseazÄƒ array-ul complet
                            array_json = '[' + array_content + ']'
                            try:
                                companies_list = json.loads(array_json)
                                for obj in companies_list:
                                    if isinstance(obj, dict) and (obj.get("nume_companie") or obj.get("domeniu")):
                                        companies.append(obj)
                                
                                if companies:
                                    logger.info(f"âœ… Metoda 3 SUCCESS: Extracted {len(companies)} companies from array")
                                    parse_success = True
                                    if self.logger and session_id:
                                        self.logger.log(
                                            session_id,
                                            "deepseek_discovery",
                                            f"âœ… JSON parsat cu succes (metoda 3): {len(companies)} companii gÄƒsite",
                                            {"parsing_method": "array_extraction", "companies_count": len(companies)}
                                        )
                            except Exception as parse_err:
                                logger.warning(f"âš ï¸ Metoda 3 - array parsing failed: {parse_err}")
                                # Fallback: Ã®ncearcÄƒ sÄƒ extragÄƒ obiecte individuale
                                objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', array_content)
                                for obj_str in objects:
                                    try:
                                        obj = json.loads(obj_str)
                                        if obj.get("nume_companie") or obj.get("domeniu"):
                                            companies.append(obj)
                                    except:
                                        continue
                                
                                if companies:
                                    logger.info(f"âœ… Metoda 3 FALLBACK SUCCESS: Extracted {len(companies)} companies")
                                    parse_success = True
                except Exception as e3:
                    logger.warning(f"âš ï¸ Metoda 3 failed: {e3}")
            
            # Metoda 4: Parsing incremental - gÄƒseÈ™te primul { È™i ultimul } valid
            if not parse_success:
                try:
                    start_idx = response_text.find('{')
                    if start_idx >= 0:
                        # GÄƒseÈ™te sfÃ¢rÈ™itul JSON-ului valid
                        brace_count = 0
                        end_idx = start_idx
                        for i in range(start_idx, len(response_text)):
                            if response_text[i] == '{':
                                brace_count += 1
                            elif response_text[i] == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    end_idx = i + 1
                                    break
                        
                        if end_idx > start_idx:
                            json_str = response_text[start_idx:end_idx]
                            data = json.loads(json_str)
                            companies = data.get("companii", [])
                            if companies:
                                logger.info(f"âœ… Metoda 4 SUCCESS: Parsed JSON incrementally - {len(companies)} companies")
                                parse_success = True
                                if self.logger and session_id:
                                    self.logger.log(
                                        session_id,
                                        "deepseek_discovery",
                                        f"âœ… JSON parsat cu succes (metoda 4): {len(companies)} companii gÄƒsite",
                                        {"parsing_method": "incremental", "companies_count": len(companies)}
                                    )
                except Exception as e4:
                    logger.warning(f"âš ï¸ Metoda 4 failed: {e4}")
            
            # DacÄƒ toate metodele au eÈ™uat, logheazÄƒ eroarea
            if not parse_success:
                logger.error(f"âŒ TOATE METODELE DE PARSING AU EÈ˜UAT!")
                logger.error(f"Response preview (first 2000 chars): {response_text[:2000]}")
                logger.error(f"Response preview (last 500 chars): {response_text[-500:]}")
                
                if self.logger and session_id:
                    self.logger.log(
                        session_id,
                        "deepseek_discovery",
                        f"âŒ EROARE: Nu s-a putut parsa JSON din rÄƒspunsul DeepSeek",
                        {
                            "response_preview_start": response_text[:500],
                            "response_preview_end": response_text[-500:],
                            "response_length": len(response_text)
                        }
                    )
            
            logger.info(f"âœ… Discovered {len(companies)} companies via DeepSeek")
            
            if self.logger and session_id:
                self.logger.log(session_id, "deepseek_discovery", f"âœ… DeepSeek a generat {len(companies)} companii. Ãncep salvarea...")
            
            # SalveazÄƒ companiile descoperite
            saved_count = 0
            saved_companies = []
            for company in companies:
                company["discovered_at"] = datetime.now(timezone.utc)
                company["source"] = "deepseek_discovery"
                company["status"] = "pending"
                self.discovered_companies_collection.update_one(
                    {"domeniu": company.get("domeniu")},
                    {"$set": company},
                    upsert=True
                )
                saved_count += 1
                saved_companies.append(company)
                
                # Log fiecare companie descoperitÄƒ
                if self.logger and session_id:
                    self.logger.log(
                        session_id,
                        "deepseek_discovery",
                        f"ğŸ“‹ Descoperit: {company.get('nume_companie', 'N/A')} ({company.get('domeniu', 'N/A')})",
                        {
                            "company": company.get("nume_companie"),
                            "domain": company.get("domeniu"),
                            "activity": company.get("activitate"),
                            "saved_count": saved_count,
                            "total": len(companies)
                        }
                    )
            
            # DacÄƒ parsing-ul a eÈ™uat dar existÄƒ companii salvate recent, le recuperÄƒm din DB
            if len(saved_companies) == 0 and not parse_success:
                logger.warning("âš ï¸ Parsing failed, but checking for recently saved companies...")
                # RecupereazÄƒ companiile salvate Ã®n ultimele 5 minute
                recent_companies = list(
                    self.discovered_companies_collection.find({
                        "discovered_at": {"$gte": datetime.now(timezone.utc) - timedelta(minutes=5)},
                        "source": "deepseek_discovery"
                    })
                )
                if recent_companies:
                    logger.info(f"âœ… Found {len(recent_companies)} recently saved companies, using them instead")
                    saved_companies = recent_companies
                    saved_count = len(recent_companies)
            
            if self.logger and session_id:
                self.logger.log(
                    session_id,
                    "deepseek_discovery",
                    f"âœ… Descoperire completÄƒ: {saved_count} companii salvate Ã®n baza de date",
                    {"total_companies": saved_count, "completed": True}
                )
            
            # ReturneazÄƒ companiile salvate (nu cele parse-uite, care pot fi goale)
            return saved_companies
            
        except Exception as e:
            logger.error(f"Error discovering companies: {e}")
            logger.error(traceback.format_exc())
            return []
    
    async def discover_companies_via_web_search(self, keywords: List[str], max_per_keyword: int = 20) -> List[Dict]:
        """
        DescoperÄƒ companii prin cÄƒutÄƒri web (Brave Search API)
        """
        try:
            from google_competitor_discovery import GoogleCompetitorDiscovery
            
            logger.info(f"ğŸ” Discovering companies via web search for {len(keywords)} keywords")
            
            discovery = GoogleCompetitorDiscovery()
            all_companies = []
            
            for keyword in keywords:
                try:
                    # CautÄƒ companii pentru acest keyword
                    results = await discovery.search_keyword(
                        keyword=keyword,
                        num_results=max_per_keyword,
                        country="RO"
                    )
                    
                    for result in results:
                        domain = result.get("domain", "")
                        if domain and domain not in [c.get("domeniu", "") for c in all_companies]:
                            all_companies.append({
                                "nume_companie": domain.replace(".ro", "").replace("www.", "").title(),
                                "domeniu": domain,
                                "activitate": keyword,
                                "oras": "RomÃ¢nia",
                                "descriere_scurta": f"Companie din domeniul {keyword}",
                                "discovered_at": datetime.now(timezone.utc),
                                "source": "web_search",
                                "status": "pending"
                            })
                    
                    # PauzÄƒ Ã®ntre cÄƒutÄƒri
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    logger.warning(f"Error searching for keyword {keyword}: {e}")
                    continue
            
            # SalveazÄƒ companiile descoperite
            for company in all_companies:
                self.discovered_companies_collection.update_one(
                    {"domeniu": company.get("domeniu")},
                    {"$set": company},
                    upsert=True
                )
            
            logger.info(f"âœ… Discovered {len(all_companies)} companies via web search")
            return all_companies
            
        except Exception as e:
            logger.error(f"Error in web search discovery: {e}")
            logger.error(traceback.format_exc())
            return []


class MassAgentCreator:
    """CreeazÄƒ agenÈ›i Ã®n masÄƒ pentru industria de construcÈ›ii"""
    
    def __init__(self, mongo_client: MongoClient, llm: LLMOrchestrator):
        self.mongo = mongo_client
        self.db = mongo_client["ai_agents_db"]
        self.llm = llm
        
        # Collections
        self.agents_collection = self.db["site_agents"]
        self.mass_creation_progress = self.db["mass_agent_creation_progress"]
        
        logger.info("âœ… Mass Agent Creator initialized")
    
    async def create_agent_for_company(self, company: Dict, priority: int = 0) -> Dict:
        """
        CreeazÄƒ un agent master pentru o companie
        
        Args:
            company: Dict cu datele companiei
            priority: Prioritate (0 = normal, 1 = high)
        
        Returns:
            Dict cu rezultatul creÄƒrii
        """
        try:
            domain = company.get("domeniu", "")
            if not domain:
                return {"success": False, "error": "No domain provided"}
            
            # VerificÄƒ dacÄƒ agentul existÄƒ deja
            existing = self.agents_collection.find_one({"domain": domain})
            if existing:
                return {
                    "success": True,
                    "agent_id": str(existing["_id"]),
                    "status": "already_exists",
                    "domain": domain
                }
            
            # ConstruieÈ™te URL
            if not domain.startswith("http"):
                site_url = f"https://{domain}"
            else:
                site_url = domain
            
            logger.info(f"ğŸ—ï¸ Creating agent for {domain}...")
            
            # CreeazÄƒ agent folosind CEOMasterWorkflow
            workflow = CEOMasterWorkflow()
            result = await workflow.execute_full_workflow(site_url=site_url)
            
            if result.get("status") == "completed":
                agent_id = result.get("agent_id")
                
                # ActualizeazÄƒ compania ca procesatÄƒ
                self.db.construction_companies_discovered.update_one(
                    {"domeniu": domain},
                    {
                        "$set": {
                            "status": "agent_created",
                            "agent_id": agent_id,
                            "created_at": datetime.now(timezone.utc)
                        }
                    }
                )
                
                return {
                    "success": True,
                    "agent_id": agent_id,
                    "status": "created",
                    "domain": domain
                }
            else:
                error = result.get("error", "Unknown error")
                return {
                    "success": False,
                    "error": error,
                    "domain": domain
                }
                
        except Exception as e:
            logger.error(f"Error creating agent for {company.get('domeniu', 'unknown')}: {e}")
            logger.error(traceback.format_exc())
            return {
                "success": False,
                "error": str(e),
                "domain": company.get("domeniu", "unknown")
            }
    
    async def create_mass_agents(
        self,
        companies: List[Dict],
        max_parallel: Optional[int] = None,  # Auto-calculeazÄƒ dacÄƒ None
        batch_id: Optional[str] = None
    ) -> Dict:
        """
        CreeazÄƒ agenÈ›i Ã®n masÄƒ pentru o listÄƒ de companii
        
        Args:
            companies: Lista de companii
            max_parallel: NumÄƒrul maxim de agenÈ›i creaÈ›i Ã®n paralel (None = auto-calculeazÄƒ)
            batch_id: ID-ul batch-ului (opÈ›ional)
        
        Returns:
            Dict cu rezultatele
        """
        try:
            # Auto-calculeazÄƒ max_parallel dacÄƒ nu este specificat
            if max_parallel is None:
                try:
                    from gpu_optimizer import get_gpu_optimizer
                    optimizer = get_gpu_optimizer(gpu_count=11, gpu_memory_gb=12)
                    max_parallel = optimizer.get_optimal_parallel_count("optimal")
                    logger.info(f"ğŸ¯ Auto-calculat max_parallel: {max_parallel} (optim pentru 11x RTX 3080 Ti)")
                except Exception as e:
                    logger.warning(f"âš ï¸ Could not auto-calculate max_parallel: {e}, using default 20")
                    max_parallel = 20
            
            if not batch_id:
                batch_id = f"batch_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}"
            
            logger.info(f"ğŸ—ï¸ Starting mass agent creation: {len(companies)} companies, {max_parallel} parallel, batch_id: {batch_id}")
            
            # CreeazÄƒ entry pentru tracking
            progress_entry = {
                "batch_id": batch_id,
                "total_companies": len(companies),
                "created": 0,
                "failed": 0,
                "already_exists": 0,
                "in_progress": 0,
                "started_at": datetime.now(timezone.utc),
                "status": "running"
            }
            self.mass_creation_progress.insert_one(progress_entry)
            
            # ProceseazÄƒ companiile Ã®n batch-uri paralele
            semaphore = asyncio.Semaphore(max_parallel)
            results = []
            
            async def create_with_semaphore(company):
                async with semaphore:
                    result = await self.create_agent_for_company(company)
                    results.append(result)
                    
                    # ActualizeazÄƒ progresul
                    if result.get("success"):
                        if result.get("status") == "already_exists":
                            self.mass_creation_progress.update_one(
                                {"batch_id": batch_id},
                                {"$inc": {"already_exists": 1}}
                            )
                        else:
                            self.mass_creation_progress.update_one(
                                {"batch_id": batch_id},
                                {"$inc": {"created": 1}}
                            )
                    else:
                        self.mass_creation_progress.update_one(
                            {"batch_id": batch_id},
                            {"$inc": {"failed": 1}}
                        )
            
            # RuleazÄƒ toate creÄƒrile
            tasks = [create_with_semaphore(company) for company in companies]
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # FinalizeazÄƒ progresul
            self.mass_creation_progress.update_one(
                {"batch_id": batch_id},
                {
                    "$set": {
                        "status": "completed",
                        "completed_at": datetime.now(timezone.utc)
                    }
                }
            )
            
            summary = {
                "batch_id": batch_id,
                "total": len(companies),
                "created": sum(1 for r in results if r.get("success") and r.get("status") == "created"),
                "already_exists": sum(1 for r in results if r.get("success") and r.get("status") == "already_exists"),
                "failed": sum(1 for r in results if not r.get("success")),
                "results": results
            }
            
            logger.info(f"âœ… Mass agent creation completed: {summary}")
            return summary
            
        except Exception as e:
            logger.error(f"Error in mass agent creation: {e}")
            logger.error(traceback.format_exc())
            return {
                "success": False,
                "error": str(e),
                "batch_id": batch_id
            }


class ConstructionIndustryOrchestrator:
    """Orchestrator principal pentru transformarea industriei de construcÈ›ii"""
    
    def __init__(self, mongo_client: MongoClient):
        self.mongo = mongo_client
        self.db = mongo_client["ai_agents_db"]
        self.llm = LLMOrchestrator()
        
        # Initialize logger
        from industry_transformation_logger import IndustryTransformationLogger
        self.logger = IndustryTransformationLogger(mongo_client)
        
        self.discovery = ConstructionIndustryDiscovery(mongo_client, self.llm, self.logger)
        self.creator = MassAgentCreator(mongo_client, self.llm)
        
        logger.info("âœ… Construction Industry Orchestrator initialized")
    
    async def transform_entire_industry(
        self,
        discovery_method: str = "deepseek",  # "deepseek" sau "web_search"
        max_companies: int = 500,
        max_parallel_agents: int = 5,
        web_search_keywords: Optional[List[str]] = None
    ) -> Dict:
        """
        TransformÄƒ Ã®ntreaga industrie de construcÈ›ii Ã®n agenÈ›i AI
        
        Args:
            discovery_method: Metoda de descoperire ("deepseek" sau "web_search")
            max_companies: NumÄƒrul maxim de companii de descoperit
            max_parallel_agents: NumÄƒrul maxim de agenÈ›i creaÈ›i Ã®n paralel
            web_search_keywords: Keywords pentru web search (dacÄƒ discovery_method = "web_search")
        
        Returns:
            Dict cu rezultatele transformÄƒrii
        """
        try:
            # GenereazÄƒ session ID
            session_id = f"transformation_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}"
            
            logger.info(f"ğŸ—ï¸ Starting industry transformation (session: {session_id})...")
            
            if self.logger:
                self.logger.log(session_id, "start", f"ğŸš€ Pornire transformare industrie construcÈ›ii - {max_companies} companii, {max_parallel_agents} paralel")
            
            # FAZA 1: Descoperire companii
            logger.info("ğŸ“ FAZA 1: Descoperire companii...")
            if self.logger:
                self.logger.log(session_id, "discovery_start", f"ğŸ” FAZA 1: Ãncep descoperirea companiilor (metodÄƒ: {discovery_method})")
            
            if discovery_method == "deepseek":
                companies = await self.discovery.discover_companies_via_deepseek(max_companies=max_companies, session_id=session_id)
            elif discovery_method == "web_search":
                if not web_search_keywords:
                    web_search_keywords = [
                        "constructii romania",
                        "firma constructii",
                        "proiectare constructii",
                        "instalatii sanitare",
                        "instalatii electrice",
                        "tamplarie metalica",
                        "tamplarie pvc",
                        "vopsitorie",
                        "gips-carton",
                        "parchet",
                        "faianta",
                        "constructii civile",
                        "renovari",
                        "amenajari interioare"
                    ]
                companies = await self.discovery.discover_companies_via_web_search(
                    keywords=web_search_keywords,
                    max_per_keyword=20
                )
            else:
                raise ValueError(f"Unknown discovery method: {discovery_method}")
            
            logger.info(f"âœ… Discovered {len(companies)} companies")
            
            if self.logger:
                self.logger.log(session_id, "discovery_complete", f"âœ… FAZA 1 completÄƒ: {len(companies)} companii descoperite")
            
            # FAZA 2: Creare agenÈ›i Ã®n masÄƒ
            logger.info("ğŸ“ FAZA 2: Creare agenÈ›i Ã®n masÄƒ...")
            if self.logger:
                self.logger.log(session_id, "creation_start", f"ğŸ—ï¸ FAZA 2: Ãncep crearea agenÈ›ilor ({max_parallel_agents} paralel)")
            
            creation_result = await self.creator.create_mass_agents(
                companies=companies,
                max_parallel=max_parallel_agents
            )
            
            logger.info("âœ… Industry transformation completed!")
            
            if self.logger:
                self.logger.log(
                    session_id,
                    "complete",
                    f"âœ… Transformare completÄƒ: {creation_result.get('created', 0)} agenÈ›i creaÈ›i, {creation_result.get('failed', 0)} eÈ™uate",
                    creation_result
                )
            
            return {
                "success": True,
                "session_id": session_id,
                "discovery": {
                    "method": discovery_method,
                    "companies_discovered": len(companies)
                },
                "creation": creation_result,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error transforming industry: {e}")
            logger.error(traceback.format_exc())
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

